<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>特許クリアランス調査レポート</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: 'Times New Roman', 'Noto Serif JP', 'Yu Mincho', serif;
            font-size: 10.5pt;
            line-height: 1.8;
            color: #111;
            background: #f5f5f5;
        }
        .toolbar {
            position: sticky; top: 0; z-index: 10;
            background: #1a1a2e; color: #ccc; padding: 10px 24px;
            display: flex; align-items: center; justify-content: space-between;
            font-family: sans-serif; font-size: 13px;
        }
        .toolbar button {
            background: #4a4aff; color: #fff; border: none; padding: 6px 16px;
            border-radius: 6px; cursor: pointer; font-size: 13px;
        }
        .toolbar button:hover { background: #6060ff; }
        article {
            max-width: 780px; margin: 30px auto; background: #fff;
            padding: 60px 64px; box-shadow: 0 2px 12px rgba(0,0,0,0.1);
        }
        h1 { font-size: 16pt; font-weight: bold; text-align: center; margin-bottom: 0.5em; }
        .authors { text-align: center; font-size: 11pt; margin-bottom: 2em; color: #333; }
        .abstract { background: #f8f9fa; border-left: 3px solid #666; padding: 1em 1.5em; margin: 1.5em 0; font-size: 9.5pt; }
        .abstract-title { font-weight: bold; margin-bottom: 0.5em; }
        h2 { font-size: 13pt; font-weight: bold; border-bottom: 1px solid #ccc; padding-bottom: 0.3em; margin-top: 2em; margin-bottom: 0.8em; }
        h3 { font-size: 11pt; font-weight: bold; margin-top: 1.5em; margin-bottom: 0.5em; color: #222; }
        h4 { font-size: 10.5pt; font-weight: bold; margin-top: 1em; margin-bottom: 0.3em; color: #333; }
        p { text-indent: 1em; margin-bottom: 0.8em; text-align: justify; }
        p.no-indent { text-indent: 0; }
        ul, ol { margin: 0.5em 0 0.8em 2em; }
        li { margin-bottom: 0.3em; }
        table { width: 100%; border-collapse: collapse; margin: 1em 0; font-size: 9.5pt; }
        table th { background: #f0f0f0; border: 1px solid #ccc; padding: 6px 10px; text-align: left; font-weight: bold; }
        table td { border: 1px solid #ccc; padding: 6px 10px; }
        caption { font-size: 9pt; margin-bottom: 0.5em; color: #555; caption-side: top; text-align: left; }
        .formula { text-align: center; margin: 1em 0; font-family: 'Cambria Math', serif; font-style: italic; }
        .todo-box {
            background: #fff3cd; border: 1px dashed #ffc107; padding: 1em;
            margin: 1em 0; border-radius: 4px; font-size: 9.5pt; color: #856404;
        }
        .todo-box::before { content: '[ TODO ] '; font-weight: bold; }
        .ref-list { font-size: 9pt; }
        .ref-list li { margin-bottom: 0.5em; text-indent: -2em; padding-left: 2em; }
        figure { text-align: center; margin: 1.5em 0; }
        figcaption { font-size: 9pt; color: #555; margin-top: 0.5em; }
        sup { font-size: 7.5pt; }
        @media print {
            .toolbar { display: none !important; }
            body { background: white; }
            article { box-shadow: none; margin: 0; padding: 40px 50px; max-width: none; }
        }
    </style>
</head>
<body>

<div class="toolbar">
    <span>特許クリアランス調査レポート</span>
    <button onclick="window.print()">印刷 / PDF出力</button>
</div>

<article>

    <h1>テキストマイニングと機械学習を用いた<br>特許クリアランス調査の自動化に関する適合性評価</h1>

    <div class="authors">
        <div class="todo-box">著者名・所属を記入</div>
    </div>

    <!-- Abstract -->
    <div class="abstract">
        <div class="abstract-title">概要</div>
        <p class="no-indent">
            本稿では、自然言語処理（NLP）と機械学習を組み合わせた特許クリアランス調査の自動化手法について、
            自部門の実務データへの適合性を評価した結果を報告する。
            Azure OpenAI Service を用いて特許公報番号から各セクション（タイトル、要約、請求項、明細書）の
            構造化テキストを取得し、TF-IDFやDoc2Vec等のテキストベクトル化手法、
            コサイン類似度に基づく類似特許検索、及びランダムフォレスト等のアンサンブル機械学習分類器
            といった確立された技術を組み合わせ、
            自部門で取り扱う特許文書に対してどの程度の精度で類似特許の検出と関連度判定が可能かを検証した。
            本評価を通じて、既存手法の実務適用における有効性と限界を明らかにし、
            自部門におけるクリアランス調査業務の効率化の見通しを示す。
        </p>
        <p class="no-indent" style="margin-top:0.5em">
            <strong>キーワード：</strong>特許クリアランス調査、Azure OpenAI Service、テキストマイニング、TF-IDF、コサイン類似度、機械学習分類器、適合性評価
        </p>
    </div>

    <!-- 1. Introduction -->
    <h2>1. はじめに</h2>

    <h3>1.1 背景</h3>
    <p>
        製品開発や技術研究において、他者の特許権を侵害するリスクを事前に評価する「クリアランス調査」は、
        知的財産戦略の根幹をなす作業である。
        従来のクリアランス調査では、特許検索データベース（J-PlatPat等）を用いて専門家が手動で類似特許を
        検索・評価するが、この作業は高度な専門知識と多大な時間を要する。
    </p>
    <p>
        近年、自然言語処理（NLP）技術と機械学習の分野では、TF-IDF<sup>[1]</sup>、Word2Vec<sup>[2]</sup>、
        Doc2Vec<sup>[3]</sup>等のテキストベクトル化手法や、ランダムフォレスト<sup>[5]</sup>、
        SVM<sup>[7]</sup>等の分類アルゴリズムが広く研究され、多くの応用分野で有効性が実証されている。
        特許文書へのテキストマイニング適用に関しても、Tseng et al. (2007)<sup>[9]</sup>が
        その技術と課題を体系的に整理している。
        しかし、これらの手法が自部門で扱う日本語特許文書に対してどの程度有効に機能するかは、
        実際にデータを用いて検証しなければ判断できない。
    </p>

    <h3>1.2 目的</h3>
    <p>
        本稿の目的は、既に確立されたテキストマイニング・機械学習手法を自部門の特許クリアランス調査に適用し、
        以下の点を明らかにすることである。
    </p>
    <ol>
        <li>各ベクトル化手法（TF-IDF, Doc2Vec, Word2Vec）が自部門の特許文書でどの程度の検索精度を示すか</li>
        <li>コサイン類似度に基づく類似特許ランキングが実務上の判断基準として十分な精度を持つか</li>
        <li>機械学習分類器による関連特許の自動判別がどの程度信頼できるか</li>
    </ol>
    <p>
        なお、本稿で使用する個々の手法に新規性はなく、いずれも先行研究で提案・評価済みの技術である。
        本稿の貢献は、これらの手法を自部門の実務データに適用した際の精度・実用性に関する知見の提供にある。
    </p>

    <h3>1.3 本稿の構成</h3>
    <p>
        第2章で関連技術を概説し、第3章で評価に使用した手法の詳細を述べる。
        第4章でシステムの実装について説明し、第5章で評価実験の結果を報告する。
        第6章で考察を行い、第7章で結論を述べる。
    </p>

    <!-- 2. Related Work -->
    <h2>2. 関連技術</h2>

    <h3>2.1 テキストベクトル化手法</h3>
    <p>
        文書のベクトル化は情報検索分野における中心的な技術である。
        Robertson (2004) が理論的に基礎づけたTF-IDFは、単語の出現頻度と逆文書頻度の積により単語の重要度を定量化する
        手法であり、多くの応用で有効性が示されている<sup>[1]</sup>。
    </p>
    <p>
        分散表現に基づく手法として、Mikolov et al. (2013) のWord2Vecは、
        単語をCBOWまたはSkip-gramモデルで低次元の密ベクトルに写像する<sup>[2]</sup>。
        Le &amp; Mikolov (2014) は、Word2Vecを文書レベルに拡張したDoc2Vec（Paragraph Vector）を提案し、
        PV-DM（Distributed Memory）とPV-DBOW（Distributed Bag of Words）の2つのアーキテクチャを
        示した<sup>[3]</sup>。
    </p>

    <h3>2.2 特許文書の類似度計算</h3>
    <p>
        特許文書の類似度計算に関しては、Helmers et al. (2019) が特許文書の構造的特徴（タイトル、要約、請求項、明細書）を
        活用した重み付きベクトル化手法の有効性を報告している<sup>[4]</sup>。
        コサイン類似度は高次元ベクトル空間における標準的な類似度尺度であり、
        ベクトルの方向のみに依存し文書長の差異に対して頑健な指標である。
    </p>

    <h3>2.3 機械学習による文書分類</h3>
    <p>
        テキスト分類タスクにおけるアンサンブル学習法の有効性は多くの研究で確認されている。
        Breiman (2001) のランダムフォレスト<sup>[5]</sup>、Friedman et al. (2000) が統計的に定式化した
        AdaBoost<sup>[6]</sup>は、高次元なテキスト分類において優れた性能を示すことが報告されている。
        SVMも LIBSVM<sup>[7]</sup>等の実装を通じて幅広い分野で活用されている。
    </p>

    <!-- 3. Evaluated Methods -->
    <h2>3. 評価対象手法</h2>

    <h3>3.1 システム構成</h3>
    <p>
        評価に使用したシステムは、以下の5つのモジュールで構成される（図1）。
        各モジュールの実装には既存のライブラリ・アルゴリズム・クラウドAPIをそのまま使用し、手法自体の改変は行っていない。
    </p>
    <ol>
        <li><strong>データ取得モジュール：</strong>特許公報番号を入力とし、Azure OpenAI Service APIを介して特許文書の構造化要約（タイトル、要約、請求項、明細書）を生成</li>
        <li><strong>前処理モジュール：</strong>Janome形態素解析器による日本語トークン化とフィルタリング</li>
        <li><strong>ベクトル化モジュール：</strong>scikit-learn TF-IDF / Gensim Doc2Vec, Word2Vecによるテキストのベクトル変換</li>
        <li><strong>類似度計算モジュール：</strong>コサイン類似度に基づく検索・ランキング</li>
        <li><strong>分類モジュール：</strong>scikit-learn分類器による関連度の自動判別</li>
    </ol>

    <figure>
        <div style="background: #f5f5f5; border: 1px solid #ddd; padding: 1.5em; font-family: monospace; font-size: 8.5pt; text-align: left; white-space: pre; line-height: 1.5; overflow-x: auto;">
特許公報番号（JP2018-XXXXXX 等）
         │
         ▼
┌──────────────────────────────┐
│  0. データ取得（Azure OpenAI） │  公報番号 → LLM要約生成
│     構造化テキスト抽出         │  → タイトル / 要約 / 請求項 / 明細書
└──────────┬───────────────────┘
         ▼
┌──────────────────────────────┐
│  1. 前処理（形態素解析）       │  Janome → 名詞抽出 → ストップワード除去
│     セクション重み付け          │  請求項(×5) &gt; タイトル(×3) &gt; 要約(×2) &gt; 明細書(×1)
└──────────┬───────────────────┘
         ▼
┌──────────────────────────────┐
│  2. ベクトル化                 │  TF-IDF / Doc2Vec / Word2Vec
│     （次元削減: LSA/PCA）      │
└──────────┬───────────────────┘
         ▼
┌──────────────────────────────┐
│  3. 類似度計算・ランキング     │  コサイン類似度
│     多重クエリ集約             │  最大 / 平均 / 結合ベクトル
│     構成要素マッピング         │  請求項要素→候補文のマッチング
└──────────┬───────────────────┘
         ▼
┌──────────────────────────────┐
│  4. 機械学習分類              │  RF / AdaBoost / SVM / MLP 等
│     適合判定予測               │  (11種アルゴリズム比較)
└──────────────────────────────┘</div>
        <figcaption>図1：評価システムの全体構成</figcaption>
    </figure>

    <h3>3.2 Azure OpenAI Serviceによる特許文書の構造化取得</h3>
    <p>
        本システムでは、特許公報番号を入力として、Azure OpenAI Service（GPTモデル）を介して
        特許文書の各セクション（タイトル、要約、請求項、明細書）を構造化テキストとして取得する。
        具体的には、公報番号をプロンプトに含めてAPIリクエストを送信し、
        大規模言語モデル（LLM）が持つ特許文書の知識に基づいて各セクションの内容を要約・生成する。
    </p>
    <p>
        この手法により、特許データベースからのスクレイピングや手動でのテキスト抽出を行うことなく、
        公報番号のリストのみから分析に必要な構造化テキストを一括取得できる。
        Azure OpenAI Serviceを利用することで、企業のセキュリティポリシーに適合した
        クラウド環境でのデータ処理が可能であり、データの地理的な所在管理も行える。
    </p>
    <p>
        なお、LLMによる要約は原文の忠実な転記ではなく、モデルが学習した知識に基づく再構成であるため、
        出力テキストの正確性には一定の限界がある。この点は6.6節の課題として議論する。
    </p>

    <h3>3.3 日本語特許文書の前処理</h3>

    <h4>3.3.1 形態素解析</h4>
    <p>
        日本語テキストは英語と異なり明示的な単語区切りが存在しないため、形態素解析器によるトークン化が必要である。
        本システムでは、Janome形態素解析器を使用し、名詞（一般名詞）のみを抽出する。
        非自立名詞、代名詞、数詞、接尾辞等のサブカテゴリは除外し、
        各トークンの基本形（辞書形）で表記の正規化を行う。
    </p>

    <h4>3.3.2 ストップワード除去</h4>
    <p>
        ストップワードとして、一般的な日本語機能語（37語）に加え、特許文書に頻出する定型表現（26語）を定義した。
        「発明」「特許」「請求」「実施」「形態」等、特許文書に頻出するが
        技術内容の弁別に寄与しない語彙が含まれる。
    </p>

    <h4>3.3.3 セクション重み付け</h4>
    <p>
        Helmers et al.<sup>[4]</sup>の知見に基づき、特許文書のセクション毎に異なる重みを設定した（表1）。
        特許文書 <em>d</em> のセクション集合を S = {claims, title, abstract, description} とし、
        各セクション <em>s</em> から抽出されたトークン列を tokens(<em>d</em>, <em>s</em>)、
        重み係数を <em>w<sub>s</sub></em> とする。
        重み付き文書トークン列 T(<em>d</em>) を次式で定義する。
    </p>
    <div class="formula">
        T(d) = ⨁<sub>s∈S</sub> tokens(d, s)<sup>⊕w<sub>s</sub></sup>
    </div>
    <p>
        ここで ⊕ は系列の結合（concatenation）演算、上付き ⊕<em>w</em> は系列の <em>w</em> 回反復結合を表す。
        これにより、重み <em>w<sub>s</sub></em> を持つセクションのトークンは出現頻度が <em>w<sub>s</sub></em> 倍となり、
        TF-IDFの TF(t, d) に対して間接的な重み付けが実現される。
        具体的には、セクション <em>s</em> に含まれる単語 <em>t</em> の重み付き後の出現回数は
        count'(t, d) = Σ<sub>s∈S</sub> w<sub>s</sub> · count(t, d, s) となる。
    </p>

    <table>
        <caption>表1：セクション別重み付け</caption>
        <thead>
            <tr><th>セクション</th><th>重み</th><th>設定根拠</th></tr>
        </thead>
        <tbody>
            <tr><td>請求項（Claims）</td><td>5</td><td>発明の法的保護範囲を規定する核心部分</td></tr>
            <tr><td>タイトル（Title）</td><td>3</td><td>発明を簡潔に特定する識別情報</td></tr>
            <tr><td>要約（Abstract）</td><td>2</td><td>技術的概要の要約</td></tr>
            <tr><td>明細書（Description）</td><td>1</td><td>実施形態の詳細記述（基準重み）</td></tr>
        </tbody>
    </table>

    <h3>3.4 テキストベクトル化</h3>

    <h4>3.4.1 TF-IDF</h4>
    <p>
        TF-IDF（Term Frequency-Inverse Document Frequency）はRobertson (2004)<sup>[1]</sup>が理論的基盤を整理した
        重み付け手法である。コーパス D = {d<sub>1</sub>, ..., d<sub>N</sub>} 中の文書 d に含まれる語 t の重みを以下で定義する。
        本評価ではサブリニアTFスケーリングを適用した。
    </p>
    <div class="formula">
        TF(t, d) = 1 + log<sub>e</sub>(count(t, d)) &nbsp;&nbsp;（count(t, d) &gt; 0 のとき、0 otherwise）
    </div>
    <div class="formula">
        IDF(t) = log<sub>e</sub>(N / df(t)) + 1 &nbsp;&nbsp;（df(t) = |{d ∈ D : t ∈ d}|）
    </div>
    <div class="formula">
        tfidf(t, d) = TF(t, d) &times; IDF(t)
    </div>
    <p>
        ここで N = |D| は全文書数、df(t) は語 t を含む文書数（文書頻度）である。
        サブリニアTFスケーリングにより、高頻度語の影響が対数的に抑制される。
        各文書 d は語彙集合 V = {t<sub>1</sub>, ..., t<sub>|V|</sub>} 上のベクトル
        <strong>v</strong><sub>d</sub> = (tfidf(t<sub>1</sub>, d), ..., tfidf(t<sub>|V|</sub>, d))
        ∈ ℝ<sup>|V|</sup> として表現される。
        類似度計算に先立ち L2正規化を適用する。
    </p>
    <div class="formula">
        <strong>v̂</strong><sub>d</sub> = <strong>v</strong><sub>d</sub> / ‖<strong>v</strong><sub>d</sub>‖<sub>2</sub>
        &nbsp;&nbsp;（‖<strong>v</strong>‖<sub>2</sub> = √(Σ<sub>i</sub> v<sub>i</sub><sup>2</sup>)）
    </div>
    <p>
        L2正規化により各文書ベクトルが単位超球面 S<sup>|V|−1</sup> 上に射影され、
        文書長の影響が除去される。
        ユニグラムとバイグラムの両方を特徴量とし（ngram_range=(1,2)）、最大特徴数は10,000とした。
        特徴量空間の次元を |V'| ≤ 10,000 に制限することで計算効率と過学習抑制を図る。
    </p>

    <h4>3.4.1.1 潜在意味解析（LSA）による次元削減</h4>
    <p>
        Dumais (2004)<sup>[8]</sup>が包括的にレビューした LSA（Latent Semantic Analysis）による
        次元削減も併せて評価した。
        TF-IDF行列を A ∈ ℝ<sup>N×|V'|</sup>（N: 文書数、|V'|: 特徴語数）とし、
        切断特異値分解（Truncated SVD）を適用する。
    </p>
    <div class="formula">
        A ≈ U<sub>k</sub> Σ<sub>k</sub> V<sub>k</sub><sup>T</sup>
    </div>
    <p>
        ここで U<sub>k</sub> ∈ ℝ<sup>N×k</sup> は左特異ベクトル行列、
        Σ<sub>k</sub> ∈ ℝ<sup>k×k</sup> は上位 k 個の特異値からなる対角行列、
        V<sub>k</sub> ∈ ℝ<sup>|V'|×k</sup> は右特異ベクトル行列であり、
        Eckart-Young-Mirsky の定理により、この近似はフロベニウスノルム ‖A − U<sub>k</sub>Σ<sub>k</sub>V<sub>k</sub><sup>T</sup>‖<sub>F</sub>
        を最小化する最良ランク k 近似である。
        低次元表現 A<sub>k</sub> = U<sub>k</sub>Σ<sub>k</sub> ∈ ℝ<sup>N×k</sup> により、
        同義語・多義語の問題が潜在意味空間への射影を通じて軽減される。
    </p>

    <h4>3.4.2 Doc2Vec</h4>
    <p>
        Doc2Vec（Paragraph Vector）は Le &amp; Mikolov (2014)<sup>[3]</sup>による文書レベルの分散表現学習手法である。
        文書 d に対するベクトル <strong>p</strong><sub>d</sub> ∈ ℝ<sup>m</sup>（m = 200）を学習する。
        本評価では2つのアーキテクチャを評価した。
    </p>
    <p>
        <strong>PV-DBOW</strong>（dm=0）: 文書ベクトル <strong>p</strong><sub>d</sub> のみから文書内の単語 w<sub>t</sub> を予測するモデルである。
        目的関数は文書 d に含まれる全単語に対する対数尤度の最大化として定義される。
    </p>
    <div class="formula">
        L<sub>DBOW</sub> = Σ<sub>d∈D</sub> Σ<sub>w<sub>t</sub>∈d</sub> log P(w<sub>t</sub> | <strong>p</strong><sub>d</sub>)
    </div>
    <p>
        <strong>PV-DM</strong>（dm=1）: 文書ベクトル <strong>p</strong><sub>d</sub> と文脈語ベクトル
        {<strong>u</strong><sub>w<sub>t-c</sub></sub>, ..., <strong>u</strong><sub>w<sub>t+c</sub></sub>} の結合または平均から
        中心語 w<sub>t</sub> を予測するモデルである。
    </p>
    <div class="formula">
        L<sub>DM</sub> = Σ<sub>d∈D</sub> Σ<sub>t</sub> log P(w<sub>t</sub> | <strong>p</strong><sub>d</sub>, <strong>u</strong><sub>w<sub>t-c</sub></sub>, ..., <strong>u</strong><sub>w<sub>t+c</sub></sub>)
    </div>
    <p>
        両モデルにおいて P(w<sub>t</sub> | ·) はソフトマックス関数で定義されるが、
        語彙サイズが大きい場合の計算効率のため負例サンプリング（negative sampling）で近似する。
        負例サンプリングでは、目的関数を以下に置換する（k: 負例サンプル数）。
    </p>
    <div class="formula">
        log σ(<strong>v'</strong><sub>w<sub>t</sub></sub><sup>T</sup> <strong>h</strong>) +
        Σ<sub>i=1</sub><sup>k</sup> 𝔼<sub>w<sub>i</sub>~P<sub>n</sub></sub>[log σ(−<strong>v'</strong><sub>w<sub>i</sub></sub><sup>T</sup> <strong>h</strong>)]
    </div>
    <p>
        ここで σ(x) = 1/(1 + e<sup>−x</sup>) はシグモイド関数、<strong>h</strong> は入力の隠れ層出力、
        P<sub>n</sub>(w) はノイズ分布（ユニグラム分布の3/4乗）である。
        いずれも200次元のベクトルを生成し、100エポックの学習を行った。
    </p>

    <h4>3.4.3 Word2Vec + 平均プーリング</h4>
    <p>
        Word2Vec (Mikolov et al., 2013)<sup>[2]</sup>で学習した単語ベクトル <strong>e</strong><sub>w</sub> ∈ ℝ<sup>m</sup>（m = 100）を用いる。
        Skip-gramモデルの目的関数は、中心語 w<sub>t</sub> の周囲の文脈語 w<sub>t+j</sub>（|j| ≤ c, j ≠ 0）の予測確率の対数尤度として定義される。
    </p>
    <div class="formula">
        L<sub>SG</sub> = (1/T) Σ<sub>t=1</sub><sup>T</sup> Σ<sub>−c≤j≤c, j≠0</sub> log P(w<sub>t+j</sub> | w<sub>t</sub>)
    </div>
    <p>
        文書 d に含まれる n<sub>d</sub> 個の単語 {w<sub>1</sub>, ..., w<sub>n<sub>d</sub></sub>} に対し、
        文書ベクトル <strong>d</strong> を平均プーリング（mean pooling）で定義する。
    </p>
    <div class="formula">
        <strong>d</strong> = (1/n<sub>d</sub>) Σ<sub>i=1</sub><sup>n<sub>d</sub></sup> <strong>e</strong><sub>w<sub>i</sub></sub> ∈ ℝ<sup>m</sup>
    </div>
    <p>
        平均プーリングは単語ベクトルの重心に対応し、各単語に等しい重みを与える。
        TF-IDF重みによる加重平均 <strong>d</strong><sub>w</sub> = Σ<sub>i</sub> tfidf(w<sub>i</sub>, d)·<strong>e</strong><sub>w<sub>i</sub></sub> / Σ<sub>i</sub> tfidf(w<sub>i</sub>, d) も考えられるが、
        本評価では単純平均を採用した。
    </p>

    <h3>3.5 類似度計算と多重クエリ戦略</h3>

    <h4>3.5.1 コサイン類似度</h4>
    <p>
        ベクトル空間 ℝ<sup>m</sup> における2つのベクトル <strong>a</strong>, <strong>b</strong> ∈ ℝ<sup>m</sup> 間のコサイン類似度は、
        内積とL2ノルムの比として以下で定義される。
    </p>
    <div class="formula">
        cos(<strong>a</strong>, <strong>b</strong>) = (<strong>a</strong> · <strong>b</strong>) / (‖<strong>a</strong>‖<sub>2</sub> · ‖<strong>b</strong>‖<sub>2</sub>)
        = Σ<sub>i=1</sub><sup>m</sup> a<sub>i</sub>b<sub>i</sub> / (√(Σ<sub>i</sub>a<sub>i</sub><sup>2</sup>) · √(Σ<sub>i</sub>b<sub>i</sub><sup>2</sup>))
    </div>
    <p>
        一般に値域は [−1, 1] であるが、TF-IDFベクトル等の非負ベクトル（<strong>a</strong>, <strong>b</strong> ∈ ℝ<sub>≥0</sub><sup>m</sup>）
        の場合は [0, 1] となる。
        幾何学的には、コサイン類似度は2つのベクトルがなす角 θ の余弦値 cos θ に等しく、
        θ → 0 で類似度は最大値1に収束する。
    </p>
    <p>
        コサイン類似度の重要な性質として以下が挙げられる。
    </p>
    <ul>
        <li><strong>スケール不変性：</strong>任意の正の定数 α, β &gt; 0 に対し cos(α<strong>a</strong>, β<strong>b</strong>) = cos(<strong>a</strong>, <strong>b</strong>)。
            文書長の影響が自動的に正規化される。</li>
        <li><strong>L2正規化との関係：</strong>事前に L2正規化された単位ベクトル <strong>â</strong>, <strong>b̂</strong> に対し、
            cos(<strong>â</strong>, <strong>b̂</strong>) = <strong>â</strong> · <strong>b̂</strong> となり、内積の計算のみで求まる。</li>
        <li><strong>ユークリッド距離との関係：</strong>単位ベクトル間では ‖<strong>â</strong> − <strong>b̂</strong>‖<sub>2</sub><sup>2</sup> = 2(1 − cos(<strong>â</strong>, <strong>b̂</strong>))
            が成立し、コサイン類似度の最大化はユークリッド距離の最小化と等価となる。</li>
    </ul>

    <h4>3.5.2 多重クエリ集約戦略</h4>
    <p>
        自社特許クエリ集合 Q = {<strong>q</strong><sub>1</sub>, ..., <strong>q</strong><sub>n</sub>} ⊂ ℝ<sup>m</sup>（n = |Q|）と
        候補特許ベクトル <strong>c</strong> ∈ ℝ<sup>m</sup> に対し、
        集約スコア f(Q, <strong>c</strong>) ∈ [0, 1] を計算する3つの既存戦略を比較した（表2）。
    </p>

    <table>
        <caption>表2：多重クエリ集約戦略</caption>
        <thead>
            <tr><th>戦略</th><th>数学的定義</th><th>特徴</th></tr>
        </thead>
        <tbody>
            <tr>
                <td>最大スコア</td>
                <td>f<sub>max</sub>(Q, <strong>c</strong>) = max<sub>i∈{1,...,n}</sub> cos(<strong>q</strong><sub>i</sub>, <strong>c</strong>)</td>
                <td>L<sup>∞</sup>的集約。いずれかのクエリとの高類似で検出。リスク回避型。</td>
            </tr>
            <tr>
                <td>平均スコア</td>
                <td>f<sub>avg</sub>(Q, <strong>c</strong>) = (1/n) Σ<sub>i=1</sub><sup>n</sup> cos(<strong>q</strong><sub>i</sub>, <strong>c</strong>)</td>
                <td>L<sup>1</sup>的集約。ポートフォリオ全体との平均的類似度。</td>
            </tr>
            <tr>
                <td>結合ベクトル</td>
                <td><strong>q̄</strong> = (1/n) Σ<sub>i=1</sub><sup>n</sup> <strong>q</strong><sub>i</sub>,&nbsp;
                    f<sub>cen</sub>(Q, <strong>c</strong>) = cos(<strong>q̄</strong>, <strong>c</strong>)</td>
                <td>クエリ群の重心（centroid）との類似度。コンパクトな代表表現。</td>
            </tr>
        </tbody>
    </table>
    <p>
        一般に f<sub>max</sub> ≥ f<sub>avg</sub> が成立する（コサイン類似度が非負の場合）。
        f<sub>cen</sub> は重心ベクトルの方向がクエリ分布のバイアスを反映するため、
        クエリ間の分散が大きい場合に f<sub>avg</sub> とは異なるランキングを生成しうる。
    </p>

    <h4>3.5.3 請求項の構成要素分析</h4>
    <p>
        請求項を構成要素（エレメント）に分解し、
        各構成要素に対して候補特許中の最も類似する文を特定する機能を利用した。
        請求項は「請求項N」パターン及び読点・改行で分割され、
        各構成要素ベクトルと候補特許の全文ベクトルとのコサイン類似度から根拠文を出力する。
    </p>

    <h3>3.6 機械学習分類器</h3>
    <p>
        ベクトル化された特許文書の特徴ベクトル <strong>x</strong> ∈ ℝ<sup>m</sup> に対して、
        教師あり学習による二値分類（y ∈ {0, 1}、関連=1 / 無関連=0）を適用した。
        学習データ {(<strong>x</strong><sub>i</sub>, y<sub>i</sub>)}<sub>i=1</sub><sup>n</sup> から
        写像 f: ℝ<sup>m</sup> → {0, 1} を学習する。
        表3に示す11種のアルゴリズムはいずれもscikit-learn<sup>[10]</sup>で提供される既存の実装を使用した。
    </p>

    <table>
        <caption>表3：比較対象の分類アルゴリズム</caption>
        <thead>
            <tr><th>分類器</th><th>手法概要</th><th>主要パラメータ</th></tr>
        </thead>
        <tbody>
            <tr><td>ランダムフォレスト</td><td>バギング＋特徴量ランダム選択による決定木アンサンブル</td><td>n_estimators=100</td></tr>
            <tr><td>エイダブースト</td><td>指数損失の逐次最小化による適応的ブースティング</td><td>n_estimators=100</td></tr>
            <tr><td>勾配ブースティング</td><td>損失関数の負勾配への逐次フィッティング</td><td>n_estimators=100</td></tr>
            <tr><td>SVM（RBFカーネル）</td><td>ガウシアンカーネル K(<strong>x</strong>,<strong>x'</strong>) = exp(−γ‖<strong>x</strong>−<strong>x'</strong>‖²)</td><td>kernel='rbf'</td></tr>
            <tr><td>SVM（線形カーネル）</td><td>K(<strong>x</strong>,<strong>x'</strong>) = <strong>x</strong><sup>T</sup><strong>x'</strong> によるマージン最大化</td><td>kernel='linear'</td></tr>
            <tr><td>ロジスティック回帰</td><td>シグモイド関数 σ(<strong>w</strong><sup>T</sup><strong>x</strong>+b) による確率推定</td><td>max_iter=1000</td></tr>
            <tr><td>ニューラルネット (MLP)</td><td>多層パーセプトロン（ReLU活性化関数）</td><td>hidden=(300,100)</td></tr>
            <tr><td>バギング</td><td>ブートストラップ集約によるアンサンブル</td><td>n_estimators=10</td></tr>
            <tr><td>k近傍法</td><td>特徴空間上のk最近傍による多数決</td><td>k=7</td></tr>
            <tr><td>ナイーブベイズ</td><td>P(y|<strong>x</strong>) ∝ P(y)∏P(x<sub>j</sub>|y) の独立性仮定</td><td>-</td></tr>
            <tr><td>決定木</td><td>ジニ不純度 G = 1−Σp<sub>k</sub>² に基づくCART分割</td><td>デフォルト</td></tr>
        </tbody>
    </table>

    <h4>3.6.1 主要分類器の数学的定式化</h4>
    <p>
        <strong>SVM（サポートベクターマシン）：</strong>
        学習データ {(<strong>x</strong><sub>i</sub>, y<sub>i</sub>)} に対し、ヒンジ損失と正則化項の和を最小化する。
        ラベルを ỹ<sub>i</sub> ∈ {−1, +1} と再定義すると、ソフトマージンSVMの最適化問題は以下で与えられる。
    </p>
    <div class="formula">
        min<sub><strong>w</strong>,b,ξ</sub> (1/2)‖<strong>w</strong>‖<sup>2</sup> + C Σ<sub>i=1</sub><sup>n</sup> ξ<sub>i</sub>
        &nbsp;&nbsp; s.t. &nbsp; ỹ<sub>i</sub>(<strong>w</strong><sup>T</sup>φ(<strong>x</strong><sub>i</sub>) + b) ≥ 1 − ξ<sub>i</sub>, &nbsp; ξ<sub>i</sub> ≥ 0
    </div>
    <p>
        ここで φ: ℝ<sup>m</sup> → ℋ はカーネル関数 K(<strong>x</strong>, <strong>x'</strong>) = ⟨φ(<strong>x</strong>), φ(<strong>x'</strong>)⟩<sub>ℋ</sub> に対応する
        特徴写像、C &gt; 0 は正則化パラメータ、ξ<sub>i</sub> はスラック変数である。
        双対問題の解により、決定関数は f(<strong>x</strong>) = sign(Σ<sub>i</sub> α<sub>i</sub>ỹ<sub>i</sub>K(<strong>x</strong><sub>i</sub>, <strong>x</strong>) + b) と表され、
        カーネルトリックにより高次元特徴空間での明示的な計算を回避する。
    </p>
    <p>
        <strong>ロジスティック回帰：</strong>
        入力 <strong>x</strong> に対する陽性確率を P(y=1|<strong>x</strong>) = σ(<strong>w</strong><sup>T</sup><strong>x</strong> + b)
        （σ(z) = 1/(1 + e<sup>−z</sup>)）とモデル化し、交差エントロピー損失（負の対数尤度）を最小化する。
    </p>
    <div class="formula">
        L(<strong>w</strong>, b) = −(1/n) Σ<sub>i=1</sub><sup>n</sup> [y<sub>i</sub> log ŷ<sub>i</sub> + (1−y<sub>i</sub>) log(1−ŷ<sub>i</sub>)]
        + (λ/2)‖<strong>w</strong>‖<sup>2</sup>
    </div>
    <p>
        ここで ŷ<sub>i</sub> = σ(<strong>w</strong><sup>T</sup><strong>x</strong><sub>i</sub> + b)、λ は L2正則化係数である。
    </p>
    <p>
        <strong>勾配ブースティング：</strong>
        初期予測 F<sub>0</sub>(<strong>x</strong>) = argmin<sub>γ</sub> Σ<sub>i</sub> L(y<sub>i</sub>, γ) から開始し、
        各イテレーション t = 1, ..., T で擬似残差（損失関数の負勾配）に弱学習器 h<sub>t</sub> をフィッティングする。
    </p>
    <div class="formula">
        r<sub>it</sub> = −[∂L(y<sub>i</sub>, F(<strong>x</strong><sub>i</sub>)) / ∂F(<strong>x</strong><sub>i</sub>)]<sub>F=F<sub>t-1</sub></sub>
    </div>
    <div class="formula">
        F<sub>t</sub>(<strong>x</strong>) = F<sub>t−1</sub>(<strong>x</strong>) + η · h<sub>t</sub>(<strong>x</strong>)
    </div>
    <p>
        ここで η ∈ (0, 1] は学習率（shrinkage parameter）であり、過学習を抑制する。
        二値分類では対数損失 L(y, F) = −[y log σ(F) + (1−y) log(1−σ(F))] を用いる。
    </p>
    <p>
        <strong>ランダムフォレスト：</strong>
        B 本の決定木 {h<sub>b</sub>}<sub>b=1</sub><sup>B</sup> のアンサンブルであり、
        各木はブートストラップサンプル D<sub>b</sub><sup>*</sup> ⊂ D で学習される。
        各分割ノードで全 m 特徴量のうち √m 個をランダムに選択し、
        ジニ不純度 G(S) = 1 − Σ<sub>k∈{0,1}</sub> p̂<sub>k</sub><sup>2</sup>
        （p̂<sub>k</sub>: ノード内のクラス k の比率）の減少が最大となる分割を選択する。
        最終予測は多数決 ŷ = mode({h<sub>b</sub>(<strong>x</strong>)}<sub>b=1</sub><sup>B</sup>) で行う。
    </p>

    <h4>3.6.2 評価指標の定義</h4>
    <p>
        混同行列の各要素を TP（真陽性）, FP（偽陽性）, FN（偽陰性）, TN（真陰性）とする。
    </p>
    <div class="formula">
        Precision = TP / (TP + FP), &nbsp;&nbsp;
        Recall = TP / (TP + FN)
    </div>
    <div class="formula">
        F1 = 2 · Precision · Recall / (Precision + Recall) = 2TP / (2TP + FP + FN)
    </div>
    <p>
        F1スコアは Precision と Recall の調和平均であり、算術平均と異なり両指標がともに高い場合にのみ高値を示す
        （AM ≥ HM の不等式による）。
    </p>
    <p>
        AUC-ROC は閾値 τ ∈ [0, 1] を走査した際の真陽性率 TPR(τ) = TP/(TP+FN) と
        偽陽性率 FPR(τ) = FP/(FP+TN) のパラメトリック曲線 {(FPR(τ), TPR(τ))} の下側面積として定義される。
    </p>
    <div class="formula">
        AUC = ∫<sub>0</sub><sup>1</sup> TPR(FPR<sup>−1</sup>(x)) dx
    </div>
    <p>
        確率的解釈として、AUC はランダムに選んだ陽性サンプルのスコアがランダムに選んだ陰性サンプルのスコアを
        上回る確率 P(s<sub>+</sub> &gt; s<sub>−</sub>) に等しい（Mann-Whitney U統計量との等価性）。
    </p>

    <h4>3.6.3 交差検証</h4>
    <p>
        Stratified K-Fold 交差検証（K=5）を採用した。
        データ D を K 個の互いに素な部分集合 D = D<sub>1</sub> ⊔ ... ⊔ D<sub>K</sub>
        （各 D<sub>k</sub> のクラス比率が D と同一）に分割し、
        各フォールド k ∈ {1, ..., K} で D \ D<sub>k</sub> を学習データ、D<sub>k</sub> をテストデータとして
        評価指標 M<sub>k</sub> を算出する。最終評価は平均と標準偏差で報告する。
    </p>
    <div class="formula">
        M̄ = (1/K) Σ<sub>k=1</sub><sup>K</sup> M<sub>k</sub>, &nbsp;&nbsp;
        s = √((1/(K−1)) Σ<sub>k=1</sub><sup>K</sup> (M<sub>k</sub> − M̄)<sup>2</sup>)
    </div>

    <!-- 4. Implementation -->
    <h2>4. システム実装</h2>

    <h3>4.1 開発環境</h3>
    <table>
        <thead>
            <tr><th>項目</th><th>仕様</th></tr>
        </thead>
        <tbody>
            <tr><td>プログラミング言語</td><td>Python 3.x</td></tr>
            <tr><td>Webフレームワーク</td><td>Flask 3.x</td></tr>
            <tr><td>特許文書取得</td><td>Azure OpenAI Service（GPTモデル）</td></tr>
            <tr><td>形態素解析</td><td>Janome</td></tr>
            <tr><td>機械学習</td><td>scikit-learn</td></tr>
            <tr><td>分散表現</td><td>Gensim（Doc2Vec, Word2Vec）</td></tr>
            <tr><td>可視化</td><td>Plotly</td></tr>
            <tr><td>フロントエンド</td><td>Tailwind CSS, JavaScript</td></tr>
        </tbody>
    </table>

    <h3>4.2 ユーザインタフェース</h3>
    <p>
        評価の再現性と操作性を確保するため、Webブラウザベースのインタフェースを構築した。
        6つのタブ構成とし、データ登録から類似度検索、分類器学習、結果可視化までの一連のワークフローを
        画面上で実行できるようにした。
    </p>

    <!-- 5. Experiments -->
    <h2>5. 評価実験</h2>

    <h3>5.1 データセット</h3>
    <div class="todo-box">
        使用データセットの詳細を記入。
        件数（自社特許○件、候補特許○件）、正解ラベルの付与方法、データの収集期間・収集元。
    </div>

    <h3>5.2 実験条件</h3>
    <div class="todo-box">
        実験パラメータ設定を記入。
        ベクトル化手法、LSAの有無と次元数、テスト割合、交差検証の分割数、使用した集約戦略。
    </div>

    <h3>5.3 類似度検索の精度</h3>
    <div class="todo-box">
        クリアランス調査の結果を記入。
        上位N件のPrecision@K, Recall@K, 類似度スコアの分布、ベクトル化手法間の比較。
    </div>

    <h3>5.4 分類器の比較結果</h3>
    <div class="todo-box">
        各アルゴリズムのPrecision, Recall, F1, AUC-ROCの比較表。混同行列、CV-F1の平均と標準偏差。
    </div>

    <h3>5.5 ベクトル化手法の比較</h3>
    <div class="todo-box">
        TF-IDF, TF-IDF+LSA, Doc2Vec, Word2Vecの検索精度・分類精度の比較。
    </div>

    <!-- 6. Discussion -->
    <h2>6. 考察</h2>

    <h3>6.1 ベクトル化手法の適合性</h3>
    <div class="todo-box">
        自部門の特許文書に対する各ベクトル化手法の適合度を考察。
        TF-IDFのスパース表現 vs Doc2Vecの密表現の違い、LSAの効果。
    </div>

    <h3>6.2 多重クエリ戦略の比較</h3>
    <div class="todo-box">
        各戦略の実測結果に基づく比較。自部門のユースケースにはどの戦略が適しているか。
    </div>

    <h3>6.3 分類器の選定</h3>
    <div class="todo-box">
        自部門のデータ規模・特性に適した分類器はどれか。少数データでの安定性、過学習リスクの観点から議論。
    </div>

    <h3>6.4 構成要素分析の実用性</h3>
    <p>
        請求項の構成要素単位での類似度分析は、スコアだけでは得られない粒度の情報を提供する。
        各構成要素が候補特許のどの記述と対応するかを具体的に示すことで、
        専門家の判断を支援する根拠情報として機能する。
    </p>
    <div class="todo-box">
        構成要素分析の具体的な結果例とその実用性について記述。
    </div>

    <h3>6.5 従来手法に対する本アプローチのメリット</h3>
    <p>
        従来のクリアランス調査は、専門家がキーワード検索と手作業での読み込みを組み合わせて実施する
        完全手動型のプロセスであった。本アプローチには、この従来手法に対して以下のメリットが認められる。
    </p>

    <h4>6.5.1 定量的・客観的な評価基盤の提供</h4>
    <p>
        従来の手動調査では、類似度の判断は専門家の経験と主観に依存しており、
        調査精度を客観的に測定・報告することが困難であった。
        本アプローチでは、コサイン類似度、Precision、Recall、F1スコア、AUC-ROC等の定量指標により
        検索精度と分類性能を数値として把握でき、調査品質の可視化と改善サイクルの運用が可能となる。
        これは社内報告や品質管理の観点からも有用である。
    </p>

    <h4>6.5.2 網羅性の向上とスクリーニング工数の削減</h4>
    <p>
        手動調査では、調査者が想定するキーワードの範囲が検索結果を制約するため、
        異なる表現で記述された関連特許を見落とすリスクがある。
        ベクトル空間モデルに基づく類似度検索は、キーワードの完全一致を要求せず
        文書全体の意味的類似性を捕捉するため、キーワード検索では発見困難な関連特許の検出が期待できる。
        また、候補特許を類似度スコア順にランキングすることで、
        専門家が精読すべき文書を上位に集約し、スクリーニング工数を大幅に削減できる。
    </p>

    <h4>6.5.3 再現性と一貫性の確保</h4>
    <p>
        同一のデータとパラメータを入力すれば常に同一の結果が得られるため、
        調査の再現性が保証される。手動調査では調査者の体調や注意力により結果にばらつきが生じうるが、
        自動化されたパイプラインではそのような変動要因が排除される。
        また、複数の技術領域にわたるクリアランス調査を実施する場合にも、
        統一的な評価基準で一貫した品質の調査結果を提供できる。
    </p>

    <h4>6.5.4 多角的な分析の統合</h4>
    <p>
        本システムは、類似度ランキング（スクリーニング）、機械学習分類器（適合判定）、
        請求項構成要素分析（根拠の特定）の3つの分析アプローチを一つのパイプラインに統合している。
        これにより、単なるスコアリングにとどまらず、なぜ類似と判定されたのかという根拠情報を
        構成要素レベルで提示でき、専門家の最終判断を多面的に支援する。
    </p>

    <h4>6.5.5 データ取得の自動化とセキュアなクラウド活用</h4>
    <p>
        Azure OpenAI Serviceを活用することで、特許公報番号のリストのみから
        分析に必要な構造化テキスト（タイトル、要約、請求項、明細書）を自動取得できる。
        特許データベースからの手動コピーやスクレイピングが不要となり、データ準備の工数を大幅に削減できる。
        また、Azure OpenAI Serviceは企業向けのセキュリティ・コンプライアンス基盤の上で運用されるため、
        機密性の高い特許情報の取り扱いにおいても組織のセキュリティポリシーに適合しやすい。
        ベクトル化・分類等の後続処理はPythonとオープンソースライブラリ（scikit-learn<sup>[10]</sup>、Gensim等）で
        ローカル実行されるため、商用特許分析ツールへの依存も最小限に抑えられる。
    </p>

    <h4>6.5.6 アルゴリズム比較による最適化</h4>
    <p>
        11種の分類アルゴリズムを同一条件で比較する機能により、
        自部門のデータ特性に最も適したアルゴリズムを実証的に選定できる。
        データの規模や分布が変化した場合にも、比較実験を再実行するだけで最適な分類器を更新でき、
        特定のアルゴリズムに固定された商用ツールにはない柔軟性を提供する。
    </p>

    <h3>6.6 課題と限界</h3>
    <p>
        一方で、本アプローチには以下の課題と限界が確認された。
        これらは本手法固有の制約というよりも、テキストベースの自然言語処理による特許分析全般に
        共通する課題<sup>[9]</sup>を含んでいる。
    </p>

    <h4>6.6.1 LLMによる要約テキストの正確性</h4>
    <p>
        本システムは Azure OpenAI Service の LLM を用いて特許公報番号から構造化テキストを取得するが、
        LLM が生成する要約は原文の忠実な転記ではなく、モデルの学習データに基づく再構成である。
        そのため、出力に事実と異なる情報が含まれるハルシネーション（幻覚）のリスクが存在する。
        特に、請求項の文言は法的保護範囲を規定する重要な記述であり、
        原文と異なる表現で再構成された場合、後続のベクトル化・類似度計算の精度に影響を及ぼす可能性がある。
        実運用においては、LLM 出力の品質を定期的にサンプリング検証し、
        必要に応じて原文との照合を行うプロセスの併用が望ましい。
    </p>

    <h4>6.6.2 テキスト表現の限界と均等論への対応困難</h4>
    <p>
        本手法はテキストの語彙的・意味的類似性に基づいて類似特許を検出するが、
        技術的に等価でありながら全く異なる用語で記述された発明（均等論の対象となりうるケース）の
        検出には本質的な限界がある。例えば、「接着剤」と「熱溶着」は特許法上の均等物となりうるが、
        テキスト表現の類似度は低い。この種の検出には、技術知識に基づく概念レベルの対応関係の
        モデリングが必要であり、現在のベクトル空間モデルでは対応が困難である。
    </p>

    <h4>6.6.3 特許図面情報の非考慮</h4>
    <p>
        特許文書には技術内容を示す図面が含まれるが、本手法ではテキスト情報のみを利用しており、
        図面に含まれる構造情報や形状情報は分析の対象外である。
        機械部品や電子回路等、図面が技術内容の理解に不可欠な分野では、
        テキストのみの分析では重要な類似性を見落とす可能性がある。
    </p>

    <h4>6.6.4 ラベルデータの品質と取得コスト</h4>
    <p>
        機械学習分類器の性能上限は、学習データに付与されたラベルの品質に直接依存する。
        特許の関連性判断には高度な技術知識と法的知識が必要であり、
        信頼性の高いラベルを大量に取得するには相当の専門家工数を要する。
        また、ラベル付けの基準が担当者間で統一されていない場合、
        学習データにノイズが混入し分類器の性能が劣化する。
        少数の高品質ラベルデータで安定した性能を得るための手法（能動学習等）の
        導入が今後の検討課題である。
    </p>

    <h4>6.6.5 学習コーパスの規模依存性</h4>
    <p>
        Doc2VecやWord2Vec等の分散表現モデルは、学習コーパスの規模と多様性に品質が大きく左右される。
        自部門の特許文書のみでは十分なコーパス規模を確保できない場合、
        単語の意味的関係が適切に学習されず、ベクトル表現の品質が低下する。
        TF-IDFはコーパス規模への依存度が相対的に低いが、
        語彙の網羅性はやはり文書数に影響される。
    </p>

    <h4>6.6.6 ドメイン特化性と汎用性のトレードオフ</h4>
    <p>
        本評価は自部門の特定技術領域（ガスバリアフィルム関連）のデータに基づいており、
        学習したモデルやパラメータ設定がそのまま他の技術領域に転用できるとは限らない。
        技術領域ごとに使用される専門用語の体系や文書の記述スタイルが異なるため、
        新たな領域への適用時にはストップワード辞書の調整、重み付けパラメータの再設定、
        分類器の再学習が必要となる。この「領域適応コスト」は実運用上の考慮事項である。
    </p>

    <h4>6.6.7 法的判断との乖離</h4>
    <p>
        テキスト類似度や機械学習分類器が出力する「類似」「関連」の判定は、
        あくまで技術的な文面レベルの類似性に基づくものであり、
        特許法上の「侵害」の判断とは本質的に異なる。
        特許侵害の成否は、請求項の文言解釈、均等論の適用、先行技術の存在等の
        法的判断を伴うため、本システムの出力は専門家による最終判断の補助情報として
        位置づけるべきであり、自動判定の結果のみで法的結論を導くことは適切でない。
    </p>

    <h4>6.6.8 形態素解析精度の影響</h4>
    <p>
        日本語特許文書に特有の長い複合名詞（「多層ガスバリア性蒸着フィルム」等）の分割精度は
        形態素解析器の内蔵辞書に依存する。専門用語が辞書に未登録の場合、
        不適切な分割が行われ、ベクトル化の品質が低下する。
        ユーザ辞書の追加や、サブワード分割手法の採用により改善の余地があるが、
        本評価ではJanomeの標準辞書をそのまま使用している。
    </p>

    <h4>6.6.9 モデルの継続的更新の必要性</h4>
    <p>
        特許は日々新たに出願・公開されるため、候補特許データベースと学習モデルの定期的な更新が必要である。
        ベクトル化モデル（特にDoc2Vec）は新規文書の追加に伴い再学習が求められ、
        分類器も新たなラベルデータが蓄積された段階で再学習することで精度の維持・向上が期待できる。
        この継続的な運用コストは実務導入に際して考慮すべき要素である。
    </p>

    <h3>6.7 今後の展望</h3>
    <p>
        本評価で確認された課題を踏まえ、以下の方向で改善・拡張を検討する。
    </p>
    <ol>
        <li><strong>Transformerモデルの適用評価：</strong>BERTやGPT等の事前学習済み言語モデルを用いた
            ベクトル化・分類との精度比較を行い、従来手法（TF-IDF, Doc2Vec）との優位性を検証する。
            特に日本語特許に特化したドメイン適応モデルの有効性を評価する。</li>
        <li><strong>能動学習の導入：</strong>分類器が判断に迷うサンプルを優先的に専門家に提示し、
            少数のラベル付けで効率的に分類精度を向上させる能動学習フレームワークの導入を検討する。</li>
        <li><strong>技術領域の拡大：</strong>ガスバリアフィルム以外の技術領域のデータでも
            同様の評価を実施し、手法の汎用性と領域適応の要件を明らかにする。</li>
        <li><strong>図面情報の活用：</strong>OCRや画像認識技術を組み合わせ、
            特許図面からの情報抽出をパイプラインに統合する可能性を検討する。</li>
    </ol>

    <!-- 7. Conclusion -->
    <h2>7. 結論</h2>
    <p>
        本稿では、TF-IDF、Doc2Vec等のテキストベクトル化手法とランダムフォレスト等の機械学習分類器を
        組み合わせた特許クリアランス調査の自動化手法について、自部門の実務データへの適合性を評価した。
    </p>
    <div class="todo-box">
        評価結果の要約を記入。
        どの手法がどの程度の精度を示したか、実務に適用可能と判断できるか。
    </div>
    <p>
        本アプローチは、定量的な評価基盤の提供、スクリーニング工数の削減、調査の再現性・一貫性の確保
        といった点で従来の手動調査に対するメリットが認められた。
        一方で、テキスト表現の限界による均等物検出の困難さ、ラベルデータの品質依存性、
        ドメイン特化性等の課題も確認された。
        本システムの出力は専門家による最終判断の補助情報として位置づけるべきであり、
        自動判定のみで法的結論を導くものではないが、
        スクリーニングの初期段階における効率化ツールとしての実用性は十分に見込まれる。
    </p>
    <p>
        今後は、Transformerベースの言語モデルとの精度比較、能動学習の導入による少数ラベルでの
        効率的な学習、評価対象の技術領域の拡大等を通じて、さらなる精度向上と実用性の検証を進める。
    </p>

    <!-- References -->
    <h2>参考文献</h2>
    <ol class="ref-list">
        <li>Robertson, S. (2004). "Understanding Inverse Document Frequency: On Theoretical Arguments for IDF." <em>Journal of Documentation</em>, 60(5), pp.503-520.</li>
        <li>Mikolov, T., Chen, K., Corrado, G., &amp; Dean, J. (2013). "Efficient Estimation of Word Representations in Vector Space." <em>Proceedings of ICLR 2013</em>. arXiv:1301.3781.</li>
        <li>Le, Q., &amp; Mikolov, T. (2014). "Distributed Representations of Sentences and Documents." <em>Proceedings of ICML 2014</em>, pp.1188-1196.</li>
        <li>Helmers, L., Horn, F., Biegler, F., Muller, T., Schopf, J., &amp; Binder, A. (2019). "Automating the Search for a Patent's Prior Art with a Full Text Similarity Search." <em>PLoS ONE</em>, 14(3), e0212103.</li>
        <li>Breiman, L. (2001). "Random Forests." <em>Machine Learning</em>, 45(1), pp.5-32.</li>
        <li>Friedman, J., Hastie, T., &amp; Tibshirani, R. (2000). "Additive Logistic Regression: A Statistical View of Boosting." <em>The Annals of Statistics</em>, 28(2), pp.337-407.</li>
        <li>Chang, C.-C., &amp; Lin, C.-J. (2011). "LIBSVM: A Library for Support Vector Machines." <em>ACM Transactions on Intelligent Systems and Technology</em>, 2(3), Article 27, pp.1-27.</li>
        <li>Dumais, S. T. (2004). "Latent Semantic Analysis." <em>Annual Review of Information Science and Technology</em>, 38(1), pp.188-230.</li>
        <li>Tseng, Y.-H., Lin, C.-J., &amp; Lin, Y.-I. (2007). "Text Mining Techniques for Patent Analysis." <em>Information Processing and Management</em>, 43(5), pp.1216-1247.</li>
        <li>Pedregosa, F., et al. (2011). "Scikit-learn: Machine Learning in Python." <em>Journal of Machine Learning Research</em>, 12, pp.2825-2830.</li>
    </ol>

    <!-- ═══════════════════════════════════ -->
    <!-- Appendix A: 用語解説                -->
    <!-- ═══════════════════════════════════ -->
    <h2>付録A. 用語解説</h2>
    <p>
        本稿で使用する主要な技術用語について、その定義と背景を整理する。
    </p>

    <!-- A.1 自然言語処理 -->
    <h3>A.1 自然言語処理の基礎概念</h3>

    <h4>形態素解析（Morphological Analysis）</h4>
    <p>
        自然言語テキストを形態素（意味を持つ最小単位）に分割し、各形態素の品詞・活用形等を同定する処理。
        日本語は英語と異なり単語間にスペースが存在しないため、テキスト処理の前段階として形態素解析が不可欠である。
        代表的な日本語形態素解析器として、MeCab（工藤, 2005）、Janome（Pure Python実装）、Sudachi等がある。
        本評価ではJanomeを使用した。
    </p>

    <h4>トークン化（Tokenization）</h4>
    <p>
        テキストをトークン（処理単位となる文字列）に分割する処理の総称。
        英語では空白分割やサブワード分割（Byte Pair Encoding等）が用いられるが、
        日本語では形態素解析がトークン化を兼ねる。
        トークン化の粒度（文字、サブワード、単語、形態素）は下流タスクの精度に影響する。
    </p>

    <h4>ストップワード（Stop Words）</h4>
    <p>
        テキスト中に高頻度で出現するが、文書の内容的特徴の弁別に寄与しない語彙。
        一般的なストップワード（「の」「に」「は」等の助詞・助動詞）に加え、
        ドメイン固有のストップワード（特許文書における「発明」「実施」「形態」等）を定義することで、
        ノイズを低減しベクトル表現の品質を向上させる。
    </p>

    <h4>N-gram</h4>
    <p>
        テキスト中の連続するN個のトークンの組。N=1をユニグラム、N=2をバイグラム、N=3をトライグラムと呼ぶ。
        バイグラムを導入することで「ガスバリア」＋「フィルム」のような複合概念を一つの特徴量として捕捉できる。
        本評価ではユニグラムとバイグラムの両方を特徴量として使用した（ngram_range=(1,2)）。
    </p>

    <!-- A.2 ベクトル化 -->
    <h3>A.2 テキストベクトル化手法</h3>

    <h4>Bag-of-Words（BoW）</h4>
    <p>
        文書中の単語の出現回数を数え上げてベクトル化する最も基本的な手法。
        語彙数V次元のスパースベクトルが得られる。
        単語の出現順序情報は失われるが、実装が容易で計算コストが低い。
        TF-IDFの基礎となるモデルである。
    </p>

    <h4>TF-IDF（Term Frequency-Inverse Document Frequency）</h4>
    <p>
        Robertson (2004)<sup>[1]</sup>が理論的基盤を整理した単語重み付け手法。
        ある単語の文書内出現頻度TF（Term Frequency）と、
        コーパス全体における希少性IDF（Inverse Document Frequency）の積で重みを算出する。
        文書に特徴的な単語には高い値が、どの文書にも出現する一般的な語には低い値が与えられる。
        サブリニアTFスケーリング（TF = 1 + log(count)）を適用すると、高頻度語の過大な影響が抑制される。
    </p>

    <h4>Word2Vec</h4>
    <p>
        Mikolov et al. (2013)<sup>[2]</sup>が提案したニューラルネットワークベースの単語分散表現学習手法。
        CBOW（Continuous Bag-of-Words：周辺語から中心語を予測）と
        Skip-gram（中心語から周辺語を予測）の2つのアーキテクチャがある。
        学習の結果、意味的に類似する単語がベクトル空間上で近傍に配置される。
        「king - man + woman ≈ queen」のようなベクトル演算で意味関係を捕捉できることが知られる。
    </p>

    <h4>Doc2Vec（Paragraph Vector）</h4>
    <p>
        Le &amp; Mikolov (2014)<sup>[3]</sup>がWord2Vecを文書レベルに拡張した手法。
        PV-DM（Distributed Memory）は文書IDベクトルと文脈語ベクトルを結合して対象語を予測するモデルであり、
        PV-DBOW（Distributed Bag of Words）は文書IDベクトルのみから文書内の単語を予測するモデルである。
        PV-DBOWは学習が高速で、短〜中程度の文書に対して安定した性能を示すことが報告されている。
    </p>

    <h4>潜在意味解析（LSA: Latent Semantic Analysis）</h4>
    <p>
        Dumais (2004)<sup>[8]</sup>が包括的にレビューした次元削減手法。
        TF-IDF行列に対して切断特異値分解（Truncated SVD）を適用し、低次元の密行列に射影する。
        高次元スパース空間から潜在意味空間への写像により、
        同義語（異なる表記で同じ概念を指す語）や多義語（同じ表記で異なる意味を持つ語）の問題が軽減される。
    </p>

    <h4>スパース表現と密表現</h4>
    <p>
        TF-IDFが生成するベクトルは高次元（語彙数次元）かつ大部分の要素がゼロであるスパース（疎）表現である。
        一方、Word2Vec・Doc2Vecが生成するベクトルは低次元（100〜300次元）かつ全要素が非ゼロの密（Dense）表現である。
        スパース表現は解釈性が高く、密表現は意味的汎化能力に優れるとされる。
    </p>

    <!-- A.3 類似度 -->
    <h3>A.3 類似度計算</h3>

    <h4>コサイン類似度（Cosine Similarity）</h4>
    <p>
        2つのベクトル間の角度の余弦値として定義される類似度指標。
        値域は[-1, 1]であるが、TF-IDFベクトル等の非負ベクトルの場合は[0, 1]となる。
        ベクトルの大きさ（ノルム）に依存せず方向のみで類似性を評価するため、
        文書長の差異に対して頑健である点が情報検索における採用理由である。
    </p>

    <h4>ユークリッド距離（Euclidean Distance）</h4>
    <p>
        ベクトル空間における2点間の直線距離。最も直感的な距離尺度であるが、
        高次元空間では「次元の呪い」により距離の弁別力が低下する傾向がある。
        また文書長の影響を受けやすいため、テキスト類似度にはコサイン類似度が一般的に好まれる。
    </p>

    <h4>Precision@K / Recall@K</h4>
    <p>
        情報検索の評価指標。上位K件の検索結果に含まれる正解文書の割合をPrecision@K、
        全正解文書のうち上位K件に含まれる割合をRecall@Kと定義する。
        クリアランス調査ではRecall（見逃しの最小化）が特に重要であり、
        Kの値を増やすことで再現率は向上するが、確認工数が増大するトレードオフが生じる。
    </p>

    <!-- A.4 機械学習 -->
    <h3>A.4 機械学習・分類手法</h3>

    <h4>教師あり学習（Supervised Learning）</h4>
    <p>
        入力データと正解ラベルのペアから入力→出力の写像関数を学習する枠組み。
        本評価では、ベクトル化された特許文書（入力）と関連/無関連のラベル（出力）から
        二値分類モデルを学習した。学習データのラベル品質が分類器の性能上限を規定する。
    </p>

    <h4>教師なし学習（Unsupervised Learning）</h4>
    <p>
        正解ラベルなしでデータの構造やパターンを発見する枠組み。
        クラスタリング（k-means等）や次元削減（PCA, SVD等）が代表的である。
        本評価においては、散布図による可視化（SVD/PCAによる2次元射影）が教師なし学習に相当する。
    </p>

    <h4>ランダムフォレスト（Random Forest）</h4>
    <p>
        Breiman (2001)<sup>[5]</sup>が提案したアンサンブル学習法。
        ブートストラップサンプリングで生成した複数のデータセットそれぞれに対して決定木を学習し、
        各決定木の予測の多数決（分類）または平均（回帰）で最終予測を行う。
        特徴量のランダム選択により各決定木の相関を低減し、汎化性能を向上させる。
        過学習に強く、ハイパーパラメータ調整の必要性が低い点が実用上の利点である。
    </p>

    <h4>AdaBoost（Adaptive Boosting）</h4>
    <p>
        Friedman et al. (2000)<sup>[6]</sup>が統計的に定式化したブースティング法。
        誤分類されたサンプルの重みを逐次的に増加させることで、弱学習器の系列を構成する。
        各イテレーションで前回の誤りを重点的に学習するため、
        学習が進むにつれて困難なサンプルに対する識別能力が向上する。
    </p>

    <h4>勾配ブースティング（Gradient Boosting）</h4>
    <p>
        勾配降下法の枠組みでブースティングを行う手法。
        各イテレーションで損失関数の負の勾配（擬似残差）に対して新たな弱学習器をフィッティングする。
        XGBoost、LightGBM等の高速実装が広く利用されている。
    </p>

    <h4>サポートベクターマシン（SVM: Support Vector Machine）</h4>
    <p>
        テキスト分類への有効性が広く確認されている判別手法であり、LIBSVM<sup>[7]</sup>等の実装を通じて普及した。
        クラス間のマージン（決定境界と最近傍サンプル間の距離）を最大化するように決定境界を学習する。
        カーネル関数（RBF、線形、多項式等）により非線形な決定境界を実現できる。
        高次元スパースデータに対して特に有効であり、テキスト分類の標準的手法の一つである。
    </p>

    <h4>ロジスティック回帰（Logistic Regression）</h4>
    <p>
        線形モデルにシグモイド関数を適用して確率値を出力する二値分類手法。
        モデルの解釈性が高く、各特徴量の寄与度を係数として直接読み取ることができる。
        L1正則化（Lasso）またはL2正則化（Ridge）によりスパース解または安定解を得る。
    </p>

    <h4>多層パーセプトロン（MLP: Multi-Layer Perceptron）</h4>
    <p>
        入力層、隠れ層、出力層からなるフィードフォワード型ニューラルネットワーク。
        隠れ層の非線形活性化関数（ReLU等）により非線形な決定境界を学習できる。
        学習データが十分に大量かつ多様な場合に高い表現力を発揮するが、
        少数データでは過学習のリスクがある。
    </p>

    <h4>バギング（Bagging: Bootstrap Aggregating）</h4>
    <p>
        ブートストラップサンプリング（復元抽出）で生成した複数のデータセットから
        個別に学習器を構築し、その予測を集約するアンサンブル手法。
        ランダムフォレストはバギングの特殊ケース（基底学習器が決定木）である。
        分散を低減し、予測の安定性を向上させる効果がある。
    </p>

    <h4>k近傍法（k-NN: k-Nearest Neighbors）</h4>
    <p>
        予測対象のデータ点に対し、特徴空間上で最も近いk個の学習データの多数決で分類を行う手法。
        モデルのパラメータ学習が不要（遅延学習）であり、
        決定境界が非線形に適応する柔軟性を持つ。
        ただし、高次元空間では「次元の呪い」により距離の弁別力が低下する。
    </p>

    <h4>ナイーブベイズ（Naive Bayes）</h4>
    <p>
        ベイズの定理に基づき、各特徴量が条件付き独立であるという（ナイーブな）仮定の下で
        事後確率を計算する分類手法。
        特徴量間の独立性仮定は現実には成立しない場合が多いが、
        テキスト分類では実用的な性能を示すことが知られている。
        学習・推論ともに計算コストが極めて低い。
    </p>

    <h4>決定木（Decision Tree）</h4>
    <p>
        特徴量の閾値に基づく条件分岐を階層的に構成し、木構造の各葉ノードでクラスラベルを出力する分類手法。
        CART（Classification and Regression Trees）アルゴリズムでは、
        ジニ不純度またはエントロピーを分割基準として貪欲に木を構築する。
        モデルの解釈性に優れるが、過学習しやすいためアンサンブル化が一般的である。
    </p>

    <!-- A.5 評価指標 -->
    <h3>A.5 評価指標</h3>

    <h4>混同行列（Confusion Matrix）</h4>
    <p>
        分類結果を真のラベルと予測ラベルの組合せで整理した2×2行列。
        真陽性（TP: True Positive）、偽陽性（FP: False Positive）、
        偽陰性（FN: False Negative）、真陰性（TN: True Negative）の4象限から構成される。
        すべての評価指標はこの行列から導出される。
    </p>

    <h4>精度（Precision）</h4>
    <p>
        陽性と予測されたサンプルのうち、実際に陽性であるものの割合。
        Precision = TP / (TP + FP)。
        クリアランス調査においては「関連と判定した候補のうち、実際に関連する割合」を意味する。
    </p>

    <h4>再現率（Recall）</h4>
    <p>
        実際に陽性であるサンプルのうち、正しく陽性と予測されたものの割合。
        Recall = TP / (TP + FN)。
        クリアランス調査においては「実際の関連特許を漏れなく検出できた割合」であり、
        見逃し（FN）が侵害リスクに直結するため、精度よりも再現率を重視する場合が多い。
    </p>

    <h4>F1スコア（F1-Score）</h4>
    <p>
        精度と再現率の調和平均。F1 = 2 &times; P &times; R / (P + R)。
        精度と再現率のバランスを単一の数値で評価する指標であり、
        クラス不均衡なデータセットにおいて正解率（Accuracy）よりも適切な評価指標となる。
    </p>

    <h4>AUC-ROC（Area Under the ROC Curve）</h4>
    <p>
        ROC曲線（Receiver Operating Characteristic Curve：偽陽性率を横軸、真陽性率を縦軸としたプロット）の
        下側面積。閾値に依存しない分類器の総合的な識別能力を示す。
        AUC=1.0は完全分類、AUC=0.5はランダム分類に相当する。
    </p>

    <h4>交差検証（Cross-Validation）</h4>
    <p>
        データをK個の部分集合（フォールド）に分割し、K-1個で学習、残り1個で評価を
        K回繰り返して性能を推定する手法。
        Stratified K-Foldでは各フォールドのクラス比率を元データと同一に保つ。
        少数データにおけるモデル評価の信頼性を向上させるが、
        計算コストがK倍になるトレードオフがある。
    </p>

    <h4>過学習（Overfitting）</h4>
    <p>
        学習データに過度に適合し、未知のデータに対する汎化性能が低下する現象。
        学習データでの精度は高いがテストデータでの精度が低い状態として顕在化する。
        正則化、早期打ち切り、アンサンブル学習等が過学習の抑制手法として知られる。
    </p>

    <!-- A.6 特許 -->
    <h3>A.6 特許関連用語</h3>

    <h4>特許クリアランス調査（FTO調査: Freedom to Operate）</h4>
    <p>
        製品や技術の実施が第三者の有効な特許権を侵害しないかを事前に評価する調査。
        侵害リスクの高い特許を特定し、設計変更やライセンス取得等の対策を検討するために実施する。
        クリアランス調査では見逃し（偽陰性）が侵害訴訟のリスクに直結するため、
        高い再現率が求められる。
    </p>

    <h4>請求項（Claims）</h4>
    <p>
        特許文書において発明の法的保護範囲を規定する部分。
        独立項と従属項からなり、各請求項は発明の技術的特徴を構成要素として列挙する。
        クリアランス調査においては、請求項の各構成要素が対象製品に含まれるかの判断が中心的な作業となる。
    </p>

    <h4>構成要素（Claim Element）</h4>
    <p>
        請求項を構成する個々の技術的特徴。
        一般に、請求項は前提部（preamble）と特徴部（characterizing portion）に分かれ、
        特徴部は複数の構成要素から成る。
        本評価システムでは、請求項を句読点や改行で分割し、
        各構成要素をa, b, c...のIDで管理する。
    </p>

    <h4>明細書（Description / Specification）</h4>
    <p>
        特許文書の本文部分。発明の技術分野、背景技術、発明の概要、実施形態の詳細な説明等が記載される。
        請求項が法的保護範囲を規定するのに対し、明細書は発明の技術的内容を当業者が実施可能な程度に開示する。
    </p>

    <h4>IPC（International Patent Classification）</h4>
    <p>
        世界知的所有権機関（WIPO）が管理する国際特許分類体系。
        セクション（A〜H）、クラス、サブクラス、メイングループ、サブグループの階層構造を持つ。
        例: C08J 5/18 は「プラスチック材料の成形品のフィルム」を表す。
    </p>

    <h4>正解公報とノイズ公報</h4>
    <p>
        教師あり学習における特許文書のラベル付け用語。
        正解公報（label=1）は調査対象技術に関連すると専門家が判断した特許を、
        ノイズ公報（label=0）は関連しないと判断された特許を指す。
        ラベルの品質（正確さ・一貫性）が分類器の性能上限を規定するため、
        専門知識を有する者によるラベル付けが望ましい。
    </p>

    <!-- A.7 実装 -->
    <h3>A.7 実装関連用語</h3>

    <h4>Azure OpenAI Service</h4>
    <p>
        Microsoft Azure 上で提供される OpenAI の大規模言語モデル（GPT-4等）のマネージドサービス。
        企業向けのセキュリティ・コンプライアンス・データプライバシー基盤の上でLLMを利用でき、
        データの地理的所在管理やアクセス制御が可能である。
        本評価システムでは、特許公報番号を入力としてAPIにリクエストを送信し、
        LLMの知識に基づいて特許文書のタイトル・要約・請求項・明細書を構造化テキストとして取得する用途に使用した。
    </p>

    <h4>ハルシネーション（Hallucination）</h4>
    <p>
        大規模言語モデルが事実と異なる情報をもっともらしく生成する現象。
        モデルは学習データの統計的パターンに基づいてテキストを生成するため、
        存在しない事実や不正確な記述を出力する場合がある。
        特許文書の要約生成においては、請求項の技術的範囲や数値条件が原文と異なる形で
        再構成されるリスクがあり、出力の品質検証が不可欠である。
    </p>

    <h4>Janome</h4>
    <p>
        Pure Pythonで実装された日本語形態素解析器。
        外部辞書のインストールが不要であり、pipコマンドのみで導入できる。
        MeCab等と比較して処理速度は劣るが、可搬性と導入の容易さが利点である。
    </p>

    <h4>scikit-learn</h4>
    <p>
        Pedregosa et al. (2011)<sup>[10]</sup>が開発したPython用機械学習ライブラリ。
        分類、回帰、クラスタリング、次元削減、モデル選択等の広範なアルゴリズムを
        統一的なAPIで提供する。本評価で使用した全分類アルゴリズムおよびTF-IDFベクトル化はscikit-learnの実装を使用した。
    </p>

    <h4>Gensim</h4>
    <p>
        トピックモデリングと文書類似度計算のためのPythonライブラリ。
        Word2Vec、Doc2Vec、FastText等の分散表現学習モデルの実装を提供する。
        本評価ではDoc2VecおよびWord2Vecの学習・推論にGensimを使用した。
    </p>

    <h4>Plotly</h4>
    <p>
        インタラクティブなグラフ・チャートを生成するJavaScript/Pythonライブラリ。
        散布図、棒グラフ、ヒートマップ等の多様なチャートタイプを、
        ズーム・パン・ホバー情報表示等のインタラクション付きで描画できる。
        本評価システムの可視化機能はPlotlyにより実装した。
    </p>

    <h4>Flask</h4>
    <p>
        PythonのマイクロWebフレームワーク。
        Jinja2テンプレートエンジンとWerkzeug WSGIツールキットを基盤とし、
        拡張性の高い軽量なWebアプリケーションを構築できる。
        本評価システムのサーバサイドはFlaskで実装した。
    </p>

</article>

</body>
</html>
