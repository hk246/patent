"""
ç‰¹è¨±ã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹èª¿æŸ»ã‚¢ãƒ—ãƒª  v2.1
è«–æ–‡å‚è€ƒ: æ–‡å­—ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã¨æ©Ÿæ¢°å­¦ç¿’ã‚’ç”¨ã„ãŸåŠ¹ç‡çš„ãªç‰¹è¨±èª¿æŸ»
(tokugikon 2018.11.26 no.291 å®‰è—¤ä¿Šå¹¸)

èµ·å‹•:
  pip install -r requirements.txt
  streamlit run app.py
"""

import sys, os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import traceback

from preprocessor import JapanesePreprocessor
from vectorizer import TFIDFDocVectorizer, VectorizerFactory, reduce_dimensions
from similarity import (
    compute_cosine_similarity, rank_patents_by_similarity,
    calculate_precision_recall, build_sentence_index,
    compute_claim_element_similarities,
)
from multi_query import (
    compute_multi_query_similarity,
    rank_candidates_multi_query,
    summarize_multi_query_results,
    STRATEGY_DESCRIPTIONS,
)
from classifier import (
    PatentClassifier, compare_classifiers,
    get_algorithm_list, get_algorithm_description,
)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ãƒšãƒ¼ã‚¸è¨­å®š
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
st.set_page_config(
    page_title="ç‰¹è¨±ã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹èª¿æŸ»ã‚·ã‚¹ãƒ†ãƒ ",
    page_icon="ğŸ”¬",
    layout="wide",
    initial_sidebar_state="expanded",
)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def init_session_state():
    defaults = {
        'company_patents': pd.DataFrame(),
        'company_preprocessed': [],
        'company_vectors': None,
        'patent_db': None,
        'preprocessed_db': [],
        'db_vectors': None,
        'vectorizer': None,
        'preprocessor': None,
        'search_results': None,
        'classifier': None,
        'multi_query_strategy': 'max',
    }
    for k, v in defaults.items():
        if k not in st.session_state:
            st.session_state[k] = v

init_session_state()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@st.cache_resource
def get_preprocessor(use_stop_words=True):
    return JapanesePreprocessor(
        pos_filter=['åè©'], min_length=2,
        use_stop_words=use_stop_words, use_patent_stop_words=True,
    )

def load_csv(uploaded, fallback_encoding='cp932') -> pd.DataFrame:
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰CSVã‚’èª­ã¿è¾¼ã‚€ï¼ˆUTF-8/CP932 è‡ªå‹•åˆ¤å®šï¼‰"""
    try:
        return pd.read_csv(uploaded, encoding='utf-8')
    except Exception:
        uploaded.seek(0)
        return pd.read_csv(uploaded, encoding=fallback_encoding)

def load_local_csv(path: str) -> pd.DataFrame | None:
    p = os.path.join(os.path.dirname(__file__), path)
    return pd.read_csv(p, encoding='utf-8') if os.path.exists(p) else None

def df_to_csv(df: pd.DataFrame) -> bytes:
    return df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')

def preprocess_rows(df: pd.DataFrame, preprocessor, weights=None) -> list:
    out = []
    for _, row in df.iterrows():
        t = preprocessor.preprocess_patent_sections(
            title=str(row.get('title','') or ''),
            abstract=str(row.get('abstract','') or ''),
            claims=str(row.get('claims','') or ''),
            description=str(row.get('description','') or ''),
            weights=weights,
        )
        out.append(t)
    return out

def run_vectorize(max_features, use_lsa, lsa_dims, vectorizer_method,
                  use_stop_words, use_claim_weight):
    """è‡ªç¤¾ç‰¹è¨±ï¼‹å€™è£œDBã‚’åŒä¸€ãƒ™ã‚¯ãƒˆãƒ«ç©ºé–“ã§å†è¨ˆç®—ã™ã‚‹å…±é€šé–¢æ•°"""
    cp = st.session_state['company_patents']
    db = st.session_state['patent_db']

    if cp.empty and db is None:
        st.warning("è‡ªç¤¾ç‰¹è¨±ãƒ»å€™è£œDBã®ã„ãšã‚Œã‹ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
        return False

    preprocessor = get_preprocessor(use_stop_words)
    st.session_state['preprocessor'] = preprocessor
    weights = {'title':3,'abstract':2,'claims':5,'description':1} if use_claim_weight else None

    company_texts = preprocess_rows(cp, preprocessor, weights) if not cp.empty else []
    db_texts = preprocess_rows(db, preprocessor, weights) if db is not None else []

    st.session_state['company_preprocessed'] = company_texts
    st.session_state['preprocessed_db'] = db_texts

    all_texts = company_texts + db_texts
    if not all_texts:
        st.warning("å‰å‡¦ç†å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ã™ã€‚")
        return False

    kwargs = {'max_features': max_features}
    if use_lsa:
        kwargs['lsa_components'] = lsa_dims
    vec = VectorizerFactory.create(vectorizer_method, **kwargs)
    vec.fit(all_texts)
    st.session_state['vectorizer'] = vec

    if company_texts:
        st.session_state['company_vectors'] = vec.transform(company_texts)
    if db_texts:
        st.session_state['db_vectors'] = vec.transform(db_texts)

    return True

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ã‚µã‚¤ãƒ‰ãƒãƒ¼
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")

    st.subheader("ãƒ™ã‚¯ãƒˆãƒ«åŒ–æ‰‹æ³•")
    vectorizer_method = st.selectbox(
        "æ‰‹æ³•",
        options=list(VectorizerFactory.METHODS.keys()),
        index=0,
    )
    st.caption(VectorizerFactory.METHODS.get(vectorizer_method,''))

    st.subheader("TF-IDFè¨­å®š")
    max_features = st.slider("æœ€å¤§ç‰¹å¾´æ•°", 1000, 30000, 10000, 1000)
    use_lsa = st.checkbox("LSAï¼ˆæ¬¡å…ƒå‰Šæ¸›ï¼‰", value=False)
    lsa_dims = st.slider("LSAæ¬¡å…ƒæ•°", 50, 500, 100, 50, disabled=not use_lsa)

    st.subheader("å‰å‡¦ç†")
    use_stop_words = st.checkbox("ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰é™¤å»", value=True)
    use_claim_weight = st.checkbox("è«‹æ±‚é …ã‚’é‡è¦–ï¼ˆé‡ã¿5å€ï¼‰", value=True)

    st.divider()
    st.subheader("è¤‡æ•°ã‚¯ã‚¨ãƒªé›†ç´„")
    strategy = st.selectbox(
        "é›†ç´„æˆ¦ç•¥",
        options=list(STRATEGY_DESCRIPTIONS.keys()),
        format_func=lambda x: STRATEGY_DESCRIPTIONS[x],
        index=0,
    )
    st.session_state['multi_query_strategy'] = strategy

    st.divider()
    if st.button("ğŸ”„ ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚’å®Ÿè¡Œ", type="primary", use_container_width=True):
        with st.spinner("ãƒ™ã‚¯ãƒˆãƒ«åŒ–ä¸­..."):
            ok = run_vectorize(max_features, use_lsa, lsa_dims,
                               vectorizer_method, use_stop_words, use_claim_weight)
            if ok:
                cp_n = len(st.session_state['company_patents'])
                db_n = len(st.session_state['patent_db']) if st.session_state['patent_db'] is not None else 0
                st.success(f"å®Œäº† è‡ªç¤¾:{cp_n}ä»¶ å€™è£œ:{db_n}ä»¶")

    st.caption("è«–æ–‡å‚è€ƒ: tokugikon 2018.11.26 no.291\nå®‰è—¤ä¿Šå¹¸ï¼ˆèŠ±ç‹æ ªå¼ä¼šç¤¾ï¼‰")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ãƒ¡ã‚¤ãƒ³UI â€“ 6ã‚¿ãƒ–æ§‹æˆ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
st.title("ğŸ”¬ ç‰¹è¨±ã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹èª¿æŸ»ã‚·ã‚¹ãƒ†ãƒ  v2.1")
st.caption("è‡ªç¤¾ç‰¹è¨±ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª Ã— æ–‡å­—ãƒ™ã‚¯ãƒˆãƒ«åŒ– Ã— æ©Ÿæ¢°å­¦ç¿’")

tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "ğŸ¢ è‡ªç¤¾ç‰¹è¨±ç™»éŒ²",
    "ğŸ“‚ å€™è£œç‰¹è¨±DB",
    "ğŸ” ã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹èª¿æŸ»",
    "ğŸ¤– åˆ†é¡å™¨å­¦ç¿’",
    "ğŸ“Š å¯è¦–åŒ–",
    "ğŸ“– å°‚é–€ç”¨èªè§£èª¬",
])


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TAB 1: è‡ªç¤¾ç‰¹è¨±ç™»éŒ²ï¼ˆCSVã®ã¿ï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab1:
    st.header("ğŸ¢ è‡ªç¤¾ç‰¹è¨±ã®ç™»éŒ²")
    st.info(
        "ã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹èª¿æŸ»ã®åŸºæº–ã¨ãªã‚‹ **è‡ªç¤¾ç‰¹è¨±** ã‚’ CSV ãƒ•ã‚¡ã‚¤ãƒ«ã§ç™»éŒ²ã—ã¾ã™ã€‚"
        "è¤‡æ•°ä»¶ç™»éŒ²ã™ã‚‹ã“ã¨ã§ã€ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå…¨ä½“ã¨ã—ã¦èª¿æŸ»ã§ãã¾ã™ã€‚"
    )

    # â”€â”€â”€ CSV ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆèª¬æ˜ â”€â”€â”€
    with st.expander("ğŸ“‹ CSV ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆã‚¯ãƒªãƒƒã‚¯ã—ã¦ç¢ºèªï¼‰", expanded=False):
        st.markdown("""
| åˆ—å | å¿…é ˆ | èª¬æ˜ |
|------|------|------|
| `patent_id` | âœ… | ç‰¹è¨±ç•ªå·ï¼ˆä¾‹: JP2020-001001ï¼‰ |
| `title` | âœ… | ç™ºæ˜ã®åç§° |
| `abstract` | ä»»æ„ | è¦ç´„ |
| `claims` | æ¨å¥¨ | è«‹æ±‚é …ï¼ˆã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹ç²¾åº¦ã«å¤§ããå½±éŸ¿ï¼‰ |
| `description` | ä»»æ„ | å®Ÿæ–½ä¾‹ãƒ»è©³ç´°èª¬æ˜ |
        """)

    col_sample, col_upload = st.columns(2)

    with col_sample:
        st.subheader("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨")
        st.caption("ã‚¬ã‚¹ãƒãƒªã‚¢ãƒ•ã‚£ãƒ«ãƒ é–¢é€£ç‰¹è¨± 5ä»¶ï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰")
        sample_cp = load_local_csv('data/sample_company_patents.csv')
        if sample_cp is not None:
            if st.button("ã‚µãƒ³ãƒ—ãƒ«è‡ªç¤¾ç‰¹è¨±ã‚’èª­ã¿è¾¼ã‚€", type="primary", use_container_width=True):
                st.session_state['company_patents'] = sample_cp
                st.session_state['company_vectors'] = None
                st.success(f"âœ… {len(sample_cp)}ä»¶ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
            with st.expander("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
                st.dataframe(sample_cp[['patent_id','title']], hide_index=True)
        else:
            st.warning("data/sample_company_patents.csv ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆDL
        template = pd.DataFrame({
            'patent_id': ['JP2020-001001', 'JP2020-001002'],
            'title': ['ç™ºæ˜ã®ã‚¿ã‚¤ãƒˆãƒ«1', 'ç™ºæ˜ã®ã‚¿ã‚¤ãƒˆãƒ«2'],
            'abstract': ['è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆ', 'è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆ'],
            'claims': ['ã€è«‹æ±‚é …1ã€‘...', 'ã€è«‹æ±‚é …1ã€‘...'],
            'description': ['å®Ÿæ–½ä¾‹ãƒ†ã‚­ã‚¹ãƒˆ', 'å®Ÿæ–½ä¾‹ãƒ†ã‚­ã‚¹ãƒˆ'],
        })
        st.download_button(
            "ğŸ“¥ CSVãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=df_to_csv(template),
            file_name="company_patents_template.csv",
            mime="text/csv",
            use_container_width=True,
        )

    with col_upload:
        st.subheader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        uploaded = st.file_uploader(
            "è‡ªç¤¾ç‰¹è¨± CSV ã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—",
            type=['csv'],
            label_visibility='collapsed',
        )
        if uploaded:
            try:
                df = load_csv(uploaded)
                if 'patent_id' not in df.columns:
                    st.error("'patent_id' åˆ—ãŒå¿…è¦ã§ã™ã€‚")
                else:
                    for col in ['title','abstract','claims','description']:
                        if col not in df.columns:
                            df[col] = ''
                    st.success(f"èª­ã¿è¾¼ã¿å®Œäº†: {len(df)}ä»¶")
                    st.dataframe(df[['patent_id','title']].head(5), hide_index=True)
                    if st.button("ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç™»éŒ²ã™ã‚‹", type="primary", use_container_width=True):
                        st.session_state['company_patents'] = df.reset_index(drop=True)
                        st.session_state['company_vectors'] = None
                        st.success(f"âœ… {len(df)}ä»¶ã‚’ç™»éŒ²ã—ã¾ã—ãŸ")
            except Exception as e:
                st.error(f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    # â”€â”€â”€ ç™»éŒ²æ¸ˆã¿ãƒªã‚¹ãƒˆ â”€â”€â”€
    st.divider()
    cp = st.session_state['company_patents']
    if cp.empty:
        st.info("è‡ªç¤¾ç‰¹è¨±ã¯ã¾ã ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    else:
        st.subheader(f"ç™»éŒ²æ¸ˆã¿è‡ªç¤¾ç‰¹è¨±: {len(cp)}ä»¶")

        # è‡ªç¤¾ç‰¹è¨±ã®ã‚µãƒ³ãƒ—ãƒ«DL
        st.download_button(
            "ğŸ“¤ ç™»éŒ²æ¸ˆã¿è‡ªç¤¾ç‰¹è¨±ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=df_to_csv(cp),
            file_name="company_patents.csv",
            mime="text/csv",
        )

        for i, row in cp.iterrows():
            c1, c2, c3 = st.columns([2, 5, 1])
            with c1:
                st.write(f"**{row.get('patent_id','')}**")
            with c2:
                st.write(str(row.get('title',''))[:80])
            with c3:
                if st.button("å‰Šé™¤", key=f"del_{i}", use_container_width=True):
                    st.session_state['company_patents'] = cp.drop(index=i).reset_index(drop=True)
                    st.session_state['company_vectors'] = None
                    st.rerun()

        st.caption("â€» ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã¯ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€ŒğŸ”„ ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚’å®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã§è¡Œã£ã¦ãã ã•ã„ã€‚")

        # ãƒ™ã‚¯ãƒˆãƒ«åŒ–çŠ¶æ…‹
        if st.session_state['company_vectors'] is not None:
            vecs = st.session_state['company_vectors']
            st.success(f"âœ… ãƒ™ã‚¯ãƒˆãƒ«åŒ–æ¸ˆã¿ï¼ˆ{vecs.shape[0]}ä»¶ Ã— {vecs.shape[1]}æ¬¡å…ƒï¼‰")
        else:
            st.warning("âš ï¸ ã¾ã ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TAB 2: å€™è£œç‰¹è¨±DBï¼ˆCSVï¼‹ã‚µãƒ³ãƒ—ãƒ«ã®ã¿ï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab2:
    st.header("ğŸ“‚ å€™è£œç‰¹è¨±ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹")
    st.info("ã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹èª¿æŸ»ã®å¯¾è±¡ã¨ãªã‚‹ **å€™è£œç‰¹è¨±** ã‚’ç™»éŒ²ã—ã¾ã™ã€‚")

    col_s, col_u = st.columns(2)

    with col_s:
        st.subheader("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨")
        st.caption("ã‚¬ã‚¹ãƒãƒªã‚¢ãƒ•ã‚£ãƒ«ãƒ é–¢é€£ç‰¹è¨± 15ä»¶ï¼ˆæ­£è§£ãƒ©ãƒ™ãƒ«ä»˜ãï¼‰")
        sample_db = load_local_csv('data/sample_patents.csv')
        if sample_db is not None:
            if st.button("ã‚µãƒ³ãƒ—ãƒ«å€™è£œç‰¹è¨±ã‚’èª­ã¿è¾¼ã‚€", type="primary", use_container_width=True):
                st.session_state['patent_db'] = sample_db
                st.session_state['db_vectors'] = None
                st.session_state['preprocessed_db'] = []
                st.success(f"âœ… {len(sample_db)}ä»¶ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
            with st.expander("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
                st.dataframe(
                    sample_db[['patent_id','title','label']].head(8),
                    hide_index=True,
                )
        else:
            st.warning("data/sample_patents.csv ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆDL
        template_db = pd.DataFrame({
            'patent_id': ['JP2020-XXXXX'],
            'title': ['ã‚¿ã‚¤ãƒˆãƒ«'],
            'abstract': ['è¦ç´„'],
            'claims': ['è«‹æ±‚é …'],
            'description': ['è©³ç´°èª¬æ˜'],
            'label': [''],
        })
        st.download_button(
            "ğŸ“¥ å€™è£œç‰¹è¨±CSVãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ",
            data=df_to_csv(template_db),
            file_name="candidate_patents_template.csv",
            mime="text/csv",
            use_container_width=True,
        )

    with col_u:
        st.subheader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        st.markdown("""
**å¿…é ˆåˆ—:** `patent_id`, `title`
**æ¨å¥¨åˆ—:** `abstract`, `claims`, `description`
**ä»»æ„åˆ—:** `label`ï¼ˆ1=é–¢é€£ã€0=ç„¡é–¢ä¿‚ï¼‰â† åˆ†é¡å™¨å­¦ç¿’ã«ä½¿ç”¨
        """)
        uploaded_db = st.file_uploader(
            "å€™è£œç‰¹è¨± CSV",
            type=['csv'],
            label_visibility='collapsed',
        )
        if uploaded_db:
            try:
                df = load_csv(uploaded_db)
                if 'patent_id' not in df.columns:
                    st.error("'patent_id' åˆ—ãŒå¿…è¦ã§ã™ã€‚")
                else:
                    for col in ['title','abstract','claims','description']:
                        if col not in df.columns:
                            df[col] = ''
                    st.success(f"èª­ã¿è¾¼ã¿å®Œäº†: {len(df)}ä»¶")
                    st.dataframe(df[['patent_id','title']].head(5), hide_index=True)
                    if st.button("ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚’å€™è£œDBã«ç™»éŒ²", type="primary", use_container_width=True):
                        st.session_state['patent_db'] = df.reset_index(drop=True)
                        st.session_state['db_vectors'] = None
                        st.session_state['preprocessed_db'] = []
                        st.success(f"âœ… {len(df)}ä»¶ã‚’ç™»éŒ²ã—ã¾ã—ãŸ")
            except Exception as e:
                st.error(f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    # â”€â”€â”€ DB ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ â”€â”€â”€
    st.divider()
    db = st.session_state['patent_db']
    if db is None:
        st.info("å€™è£œç‰¹è¨±DBã¯ã¾ã ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    else:
        st.subheader(f"å€™è£œç‰¹è¨±DB: {len(db)}ä»¶")
        disp_cols = ['patent_id', 'title']
        if 'label' in db.columns:
            disp_cols.append('label')
            vc = db['label'].value_counts()
            c1, c2, c3 = st.columns(3)
            c1.metric("ç·ä»¶æ•°", len(db))
            c2.metric("æ­£è§£(1)", int(vc.get(1,0)))
            c3.metric("ãƒã‚¤ã‚º(0)", int(vc.get(0,0)))
        st.dataframe(db[disp_cols], height=300, use_container_width=True, hide_index=True)

        if st.session_state['db_vectors'] is not None:
            vecs = st.session_state['db_vectors']
            st.success(f"âœ… ãƒ™ã‚¯ãƒˆãƒ«åŒ–æ¸ˆã¿ï¼ˆ{vecs.shape[0]}ä»¶ Ã— {vecs.shape[1]}æ¬¡å…ƒï¼‰")
        else:
            st.warning("âš ï¸ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€ŒğŸ”„ ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚’å®Ÿè¡Œã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TAB 3: ã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹èª¿æŸ»
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab3:
    st.header("ğŸ” ã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹èª¿æŸ»")

    cp = st.session_state['company_patents']
    db = st.session_state['patent_db']
    company_vecs = st.session_state['company_vectors']
    db_vecs = st.session_state['db_vectors']

    if cp.empty or company_vecs is None:
        st.info("ã‚¿ãƒ–1ã§è‡ªç¤¾ç‰¹è¨±ã‚’ç™»éŒ²ã—ã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    if db is None or db_vecs is None:
        st.info("ã‚¿ãƒ–2ã§å€™è£œç‰¹è¨±DBã‚’ç™»éŒ²ã—ã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    # â”€â”€â”€ è‡ªç¤¾ç‰¹è¨±é¸æŠ â”€â”€â”€
    st.subheader("â‘  èª¿æŸ»ã«ä½¿ç”¨ã™ã‚‹è‡ªç¤¾ç‰¹è¨±ã‚’é¸æŠ")
    all_ids = cp['patent_id'].tolist()
    selected_ids = st.multiselect(
        "ä½¿ç”¨ã™ã‚‹è‡ªç¤¾ç‰¹è¨±ï¼ˆè¤‡æ•°é¸æŠå¯ãƒ»å…¨é¸æŠãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰",
        options=all_ids, default=all_ids,
    )
    if not selected_ids:
        st.warning("1ä»¶ä»¥ä¸Šé¸æŠã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    selected_mask = cp['patent_id'].isin(selected_ids)
    selected_cp = cp[selected_mask].reset_index(drop=True)
    selected_vecs = company_vecs[selected_mask.values]

    with st.expander(f"é¸æŠä¸­: {len(selected_cp)}ä»¶ã®è‡ªç¤¾ç‰¹è¨±"):
        st.dataframe(selected_cp[['patent_id','title']], hide_index=True, use_container_width=True)

    # â”€â”€â”€ é›†ç´„æˆ¦ç•¥ â”€â”€â”€
    current_strategy = st.session_state['multi_query_strategy']
    st.info({
        'max': "**é›†ç´„: æœ€å¤§ã‚¹ã‚³ã‚¢** â€• ã„ãšã‚Œã‹ã®è‡ªç¤¾ç‰¹è¨±ã«é¡ä¼¼ã—ãŸå€™è£œãŒä¸Šä½ã«ãƒ©ãƒ³ã‚¯ã€‚ã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹ã«æœ€ã‚‚å®‰å…¨ãªé¸æŠã€‚",
        'mean': "**é›†ç´„: å¹³å‡ã‚¹ã‚³ã‚¢** â€• å…¨è‡ªç¤¾ç‰¹è¨±ã¨ã®å¹³å‡çš„ãªè¿‘ã•ã§ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€‚",
        'combined': "**é›†ç´„: çµåˆãƒ™ã‚¯ãƒˆãƒ«** â€• è‡ªç¤¾ç‰¹è¨±ãƒ™ã‚¯ãƒˆãƒ«ã®å¹³å‡ï¼ˆæŠ€è¡“é‡å¿ƒï¼‰ã‹ã‚‰ã®è·é›¢ã§ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€‚",
    }[current_strategy])

    # â”€â”€â”€ å®Ÿè¡Œ â”€â”€â”€
    st.subheader("â‘¡ é¡ä¼¼åº¦è¨ˆç®—ãƒ»ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    col_run, col_params = st.columns([3,1])
    with col_params:
        top_n = st.slider("è¡¨ç¤ºä»¶æ•°", 5, 200, 30)
        score_threshold = st.slider("æœ€ä½ã‚¹ã‚³ã‚¢é–¾å€¤", 0.0, 1.0, 0.0, 0.01)
    with col_run:
        if st.button(
            f"ğŸš€ ã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹èª¿æŸ»ã‚’å®Ÿè¡Œï¼ˆè‡ªç¤¾{len(selected_cp)}ä»¶ Ã— å€™è£œ{len(db)}ä»¶ï¼‰",
            type="primary", use_container_width=True,
        ):
            with st.spinner("é¡ä¼¼åº¦è¨ˆç®—ä¸­..."):
                try:
                    results = rank_candidates_multi_query(
                        patent_df=db,
                        query_vectors=selected_vecs,
                        candidate_vectors=db_vecs,
                        query_patents_df=selected_cp,
                        strategy=current_strategy,
                        top_n=top_n,
                        score_threshold=score_threshold,
                    )
                    st.session_state['search_results'] = results
                    st.success(f"å®Œäº†: {len(results)}ä»¶ã‚’è¡¨ç¤º")
                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
                    st.code(traceback.format_exc())

    # â”€â”€â”€ çµæœ â”€â”€â”€
    results = st.session_state['search_results']
    if results is None or results.empty:
        st.stop()

    st.divider()

    # è‡ªç¤¾ç‰¹è¨±åˆ¥ã‚µãƒãƒªãƒ¼
    if len(selected_cp) > 1:
        st.subheader("ğŸ“‹ è‡ªç¤¾ç‰¹è¨±åˆ¥ã‚µãƒãƒªãƒ¼")
        summary_df = summarize_multi_query_results(results, selected_cp)
        st.dataframe(summary_df, hide_index=True, use_container_width=True)
        st.divider()

    # ç²¾åº¦ãƒ»å†ç¾ç‡
    if 'label' in results.columns:
        st.subheader("ğŸ“ˆ ç²¾åº¦ãƒ»å†ç¾ç‡ï¼ˆPrecision / Recallï¼‰")
        pr_df = calculate_precision_recall(results)
        if not pr_df.empty and 'ã‚¨ãƒ©ãƒ¼' not in pr_df.columns:
            st.dataframe(pr_df, hide_index=True, use_container_width=True)
        st.divider()

    # ã‚¹ã‚³ã‚¢åˆ†å¸ƒ
    fig_bar = px.bar(
        results.reset_index(),
        x='index', y='similarity_score',
        color='label' if 'label' in results.columns else None,
        color_discrete_map={1:'#2ecc71', 0:'#e74c3c'},
        hover_data=['patent_id', 'title'] +
                   (['most_similar_query'] if 'most_similar_query' in results.columns else []),
        title=f"é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢åˆ†å¸ƒï¼ˆé›†ç´„: {STRATEGY_DESCRIPTIONS[current_strategy]}ï¼‰",
        labels={'index':'é †ä½', 'similarity_score':'ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦'},
    )
    st.plotly_chart(fig_bar, use_container_width=True)

    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆè¤‡æ•°ã‚¯ã‚¨ãƒªæ™‚ï¼‰
    score_cols = [c for c in results.columns if c.startswith('score_')]
    if len(score_cols) > 1:
        st.subheader("ğŸ—ºï¸ å€™è£œç‰¹è¨± Ã— è‡ªç¤¾ç‰¹è¨± é¡ä¼¼åº¦ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—")
        heat = results[['patent_id'] + score_cols].head(30).set_index('patent_id')
        heat.columns = [c.replace('score_','') for c in heat.columns]
        fig_h = px.imshow(
            heat, color_continuous_scale='RdYlGn', aspect='auto',
            title="å€™è£œç‰¹è¨±(ç¸¦) Ã— è‡ªç¤¾ç‰¹è¨±(æ¨ª) é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢",
            labels=dict(x="è‡ªç¤¾ç‰¹è¨±", y="å€™è£œç‰¹è¨±", color="é¡ä¼¼åº¦"),
        )
        st.plotly_chart(fig_h, use_container_width=True)

    # ãƒ†ãƒ¼ãƒ–ãƒ«
    st.subheader("æ¤œç´¢çµæœ")
    disp_cols = ['patent_id','title','similarity_score']
    if 'most_similar_query' in results.columns: disp_cols.append('most_similar_query')
    if 'label' in results.columns: disp_cols.append('label')
    st.dataframe(results[disp_cols], hide_index=True, use_container_width=True)

    # è©³ç´°ã‚«ãƒ¼ãƒ‰
    st.subheader("ä¸Šä½10ä»¶ è©³ç´°")
    for _, row in results.head(10).iterrows():
        with st.expander(
            f"[{row['similarity_score']:.4f}]  {row.get('patent_id','')} â€” {str(row.get('title',''))[:60]}"
        ):
            c1, c2 = st.columns([1,2])
            with c1:
                st.metric("é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢", f"{row['similarity_score']:.4f}")
                if 'most_similar_query' in row:
                    st.caption(f"æœ€é¡ä¼¼è‡ªç¤¾ç‰¹è¨±: {row['most_similar_query']}")
                if 'label' in row and pd.notna(row['label']):
                    lv = int(row['label'])
                    st.markdown(f"{'ğŸŸ¢ æ­£è§£(1)' if lv==1 else 'ğŸ”´ ãƒã‚¤ã‚º(0)'}")
                # å€‹åˆ¥ã‚¹ã‚³ã‚¢ãƒãƒ¼
                ind = {c.replace('score_',''):row[c] for c in score_cols if c in row.index}
                if ind:
                    fig_ind = px.bar(x=list(ind.values()), y=list(ind.keys()),
                                     orientation='h', range_x=[0,1],
                                     color=list(ind.values()), color_continuous_scale='RdYlGn')
                    fig_ind.update_layout(height=180, margin=dict(l=0,r=0,t=0,b=0),
                                          showlegend=False, coloraxis_showscale=False)
                    st.plotly_chart(fig_ind, use_container_width=True)
            with c2:
                st.markdown("**è«‹æ±‚é …:**")
                st.write(str(row.get('claims',''))[:400])

    st.download_button(
        "ğŸ“¥ èª¿æŸ»çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=df_to_csv(results),
        file_name="clearance_results.csv", mime="text/csv",
    )

    # æ§‹æˆè¦ç´ åˆ†æ
    st.divider()
    st.subheader("ğŸ”¬ è«‹æ±‚é …ã®æ§‹æˆè¦ç´ å˜ä½ã®é¡ä¼¼åº¦åˆ†æ")
    st.caption("è‡ªç¤¾ç‰¹è¨±ã®è«‹æ±‚é …ã‚’æ§‹æˆè¦ç´ (a,b,câ€¦)ã«åˆ†è§£ã—ã€å€™è£œç‰¹è¨±å†…ã®æ ¹æ‹ æ–‡ã‚’ç‰¹å®šã—ã¾ã™ã€‚")
    query_for_elem = st.selectbox("åˆ†æã™ã‚‹è‡ªç¤¾ç‰¹è¨±", selected_cp['patent_id'].tolist())
    if st.button("æ§‹æˆè¦ç´ åˆ†æã‚’å®Ÿè¡Œ"):
        with st.spinner("åˆ†æä¸­..."):
            try:
                q_row = selected_cp[selected_cp['patent_id']==query_for_elem].iloc[0]
                preprocessor = st.session_state['preprocessor'] or get_preprocessor()
                vec = st.session_state['vectorizer']
                elements = preprocessor.extract_claim_elements(str(q_row.get('claims','') or ''))
                if not elements:
                    st.warning("è«‹æ±‚é …ã‹ã‚‰æ§‹æˆè¦ç´ ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                else:
                    st.write(f"æ§‹æˆè¦ç´ : {len(elements)}å€‹")
                    st.dataframe(pd.DataFrame(elements)[['element_id','claim_no','text']],
                                 hide_index=True, use_container_width=True)
                    elem_vecs = vec.transform([e['preprocessed'] for e in elements])
                    sent_infos, sent_texts = build_sentence_index(results.head(10), preprocessor)
                    if sent_texts:
                        sent_vecs = vec.transform(sent_texts)
                        elem_result = compute_claim_element_similarities(
                            elements, elem_vecs, sent_infos, sent_vecs)
                        if not elem_result.empty:
                            st.dataframe(elem_result, hide_index=True, use_container_width=True)
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
                st.code(traceback.format_exc())


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TAB 4: åˆ†é¡å™¨å­¦ç¿’
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab4:
    st.header("ğŸ¤– åˆ†é¡å™¨å­¦ç¿’ï¼ˆé©åˆåˆ¤å®šï¼‰")
    st.caption("ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ï¼ˆæ­£è§£=1, ãƒã‚¤ã‚º=0ï¼‰ã§æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã€æœªãƒ©ãƒ™ãƒ«å€™è£œç‰¹è¨±ã®é–¢é€£åº¦ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚")

    db = st.session_state['patent_db']
    db_vecs = st.session_state['db_vectors']

    if db is None or db_vecs is None:
        st.info("ã‚¿ãƒ–2ã§å€™è£œç‰¹è¨±DBã‚’ç™»éŒ²ã—ã€ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    if 'label' not in db.columns:
        st.warning("å€™è£œç‰¹è¨±DBã« 'label' åˆ—ãŒå¿…è¦ã§ã™ï¼ˆ1=æ­£è§£, 0=ãƒã‚¤ã‚ºï¼‰ã€‚")
        st.stop()

    labeled_mask = db['label'].notna() & (db['label'].astype(str).str.strip() != '')
    labeled_df = db[labeled_mask].copy()
    labeled_df['label'] = labeled_df['label'].astype(int)
    unlabeled_df = db[~labeled_mask].copy()

    c1,c2,c3 = st.columns(3)
    c1.metric("ãƒ©ãƒ™ãƒ«ã‚ã‚Š", f"{len(labeled_df)}ä»¶")
    c2.metric("æ­£è§£(1)", int((labeled_df['label']==1).sum()))
    c3.metric("ãƒã‚¤ã‚º(0)", int((labeled_df['label']==0).sum()))

    if len(labeled_df) < 4:
        st.error("ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã™ãã¾ã™ï¼ˆæœ€ä½4ä»¶ï¼‰ã€‚")
        st.stop()

    col_a, col_b = st.columns(2)
    with col_a:
        algorithm = st.selectbox("åˆ†é¡ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ", get_algorithm_list(), index=1)
        st.caption(get_algorithm_description(algorithm))
    with col_b:
        test_ratio = st.slider("ãƒ†ã‚¹ãƒˆå‰²åˆ", 0.1, 0.5, 0.2, 0.05)
        cv_folds = st.slider("äº¤å·®æ¤œè¨¼åˆ†å‰²æ•°", 2, 10, 5)

    if st.button("åˆ†é¡å™¨ã‚’å­¦ç¿’ã™ã‚‹", type="primary"):
        with st.spinner("å­¦ç¿’ä¸­..."):
            try:
                from sklearn.model_selection import train_test_split
                labeled_pos = [db.index.tolist().index(i) for i in labeled_df.index]
                X_l = db_vecs[labeled_pos]
                y_l = labeled_df['label'].values
                X_tr, X_te, y_tr, y_te = train_test_split(
                    X_l, y_l, test_size=test_ratio,
                    stratify=y_l if len(np.unique(y_l))>1 else None, random_state=42)
                clf = PatentClassifier(algorithm=algorithm)
                clf.fit(X_tr, y_tr)
                st.session_state['classifier'] = clf
                ev = clf.evaluate(X_te, y_te)
                report = ev['classification_report']
                cv = clf.cross_validate(X_l, y_l, cv=cv_folds)
                m1,m2,m3,m4 = st.columns(4)
                m1.metric("æ­£è§£ç‡", f"{ev['accuracy']:.4f}")
                m2.metric("ç²¾åº¦(1)", f"{report.get('1',{}).get('precision',0):.4f}")
                m3.metric("å†ç¾ç‡(1)", f"{report.get('1',{}).get('recall',0):.4f}")
                m4.metric(f"CV-F1", f"{cv['mean']:.4f}Â±{cv['std']:.4f}")
                cm = np.array(ev['confusion_matrix'])
                fig_cm = px.imshow(cm, text_auto=True,
                    x=['ãƒã‚¤ã‚º(0)','æ­£è§£(1)'], y=['ãƒã‚¤ã‚º(0)','æ­£è§£(1)'],
                    title="æ··åŒè¡Œåˆ—", color_continuous_scale='Blues')
                st.plotly_chart(fig_cm, use_container_width=True)
                st.success("âœ… å­¦ç¿’å®Œäº†")
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
                st.code(traceback.format_exc())

    st.divider()
    st.subheader("ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æ¯”è¼ƒï¼ˆ13ç¨®é¡ï¼‰")
    sel_algos = st.multiselect("æ¯”è¼ƒã™ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ", get_algorithm_list(),
        default=['ã‚¨ã‚¤ãƒ€ãƒ–ãƒ¼ã‚¹ãƒˆ','ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ','SVM (RBFã‚«ãƒ¼ãƒãƒ«)','ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°','ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆ (MLP)'])
    if st.button("ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æ¯”è¼ƒã‚’å®Ÿè¡Œ"):
        if len(sel_algos) < 2:
            st.warning("2ä»¶ä»¥ä¸Šé¸æŠã—ã¦ãã ã•ã„ã€‚")
        else:
            with st.spinner("æ¯”è¼ƒä¸­..."):
                try:
                    from sklearn.model_selection import train_test_split
                    labeled_pos = [db.index.tolist().index(i) for i in labeled_df.index]
                    X_l = db_vecs[labeled_pos]
                    y_l = labeled_df['label'].values
                    X_tr, X_te, y_tr, y_te = train_test_split(
                        X_l, y_l, test_size=test_ratio,
                        stratify=y_l if len(np.unique(y_l))>1 else None, random_state=42)
                    cmp_df = compare_classifiers(X_tr,y_tr,X_te,y_te,algorithms=sel_algos,cv=cv_folds)
                    st.dataframe(cmp_df, hide_index=True, use_container_width=True)
                    fig = px.bar(cmp_df, x='åˆ†é¡å™¨', y='F1ã‚¹ã‚³ã‚¢(1)',
                                 color='F1ã‚¹ã‚³ã‚¢(1)', color_continuous_scale='RdYlGn',
                                 title="åˆ†é¡å™¨åˆ¥ F1ã‚¹ã‚³ã‚¢æ¯”è¼ƒ", text_auto='.4f')
                    fig.update_layout(xaxis_tickangle=-45)
                    st.plotly_chart(fig, use_container_width=True)
                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
                    st.code(traceback.format_exc())

    st.divider()
    st.subheader("æœªãƒ©ãƒ™ãƒ«å€™è£œç‰¹è¨±ã®é©åˆåˆ¤å®šäºˆæ¸¬")
    clf = st.session_state['classifier']
    if clf is None:
        st.info("å…ˆã«åˆ†é¡å™¨ã‚’å­¦ç¿’ã—ã¦ãã ã•ã„ã€‚")
    elif len(unlabeled_df) == 0:
        st.info("æœªãƒ©ãƒ™ãƒ«ã®ç‰¹è¨±ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆå…¨ä»¶ã«ãƒ©ãƒ™ãƒ«ãŒã‚ã‚Šã¾ã™ï¼‰ã€‚")
    else:
        if st.button("æœªãƒ©ãƒ™ãƒ«å€™è£œç‰¹è¨±ã‚’äºˆæ¸¬", type="primary"):
            with st.spinner("äºˆæ¸¬ä¸­..."):
                try:
                    ul_pos = [db.index.tolist().index(i) for i in unlabeled_df.index]
                    X_ul = db_vecs[ul_pos]
                    preds = clf.predict(X_ul)
                    scores = clf.predict_relevance_score(X_ul)
                    pred_df = unlabeled_df.copy()
                    pred_df['predicted_label'] = preds
                    pred_df['relevance_score'] = scores
                    pred_df = pred_df.sort_values('relevance_score', ascending=False)
                    st.success(f"äºˆæ¸¬å®Œäº†: æ­£è§£äºˆæ¸¬{int((preds==1).sum())}ä»¶ / ãƒã‚¤ã‚ºäºˆæ¸¬{int((preds==0).sum())}ä»¶")
                    st.dataframe(pred_df[['patent_id','title','predicted_label','relevance_score']],
                                 hide_index=True, use_container_width=True)
                    st.download_button("ğŸ“¥ äºˆæ¸¬çµæœCSV", data=df_to_csv(pred_df),
                                       file_name="prediction_results.csv", mime="text/csv")
                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
                    st.code(traceback.format_exc())


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TAB 5: å¯è¦–åŒ–
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab5:
    st.header("ğŸ“Š å¯è¦–åŒ–")
    st.caption("SVDã«ã‚ˆã‚‹æ¬¡å…ƒåœ§ç¸®ã§ç‰¹è¨±æ–‡æ›¸ã®ç›¸äº’é–¢ä¿‚ã‚’2Dæ•£å¸ƒå›³ã«è¡¨ç¤ºã—ã¾ã™ã€‚")

    db = st.session_state['patent_db']
    db_vecs = st.session_state['db_vectors']
    cp = st.session_state['company_patents']
    company_vecs = st.session_state['company_vectors']

    if db is None or db_vecs is None:
        st.info("ã‚¿ãƒ–2ã§ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    c1, c2 = st.columns([1,3])
    with c1:
        dim_method = st.selectbox("æ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•", ['SVD (LSA)','PCA'])
        color_by = st.selectbox("è‰²åˆ†ã‘", ['è‡ªç¤¾/å€™è£œã®åŒºåˆ¥','labelï¼ˆæ­£è§£/ãƒã‚¤ã‚ºï¼‰','é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢','ãªã—'])
        show_labels = st.checkbox("ç•ªå·ã‚’è¡¨ç¤º", value=False)

    with c2:
        if st.button("æ•£å¸ƒå›³ã‚’ç”Ÿæˆ", type="primary", use_container_width=True):
            with st.spinner("æ¬¡å…ƒå‰Šæ¸›ä¸­..."):
                try:
                    method_map = {'SVD (LSA)':'SVD','PCA':'PCA'}
                    all_vecs = db_vecs.copy()
                    all_df = db.copy(); all_df['ç¨®åˆ¥'] = 'å€™è£œç‰¹è¨±'

                    if not cp.empty and company_vecs is not None:
                        all_vecs = np.vstack([db_vecs, company_vecs])
                        cp_copy = cp.copy(); cp_copy['ç¨®åˆ¥'] = 'è‡ªç¤¾ç‰¹è¨±'
                        all_df = pd.concat([all_df, cp_copy], ignore_index=True)

                    reduced = reduce_dimensions(all_vecs, n_components=2, method=method_map[dim_method])
                    all_df['x'] = reduced[:,0]; all_df['y'] = reduced[:,1]

                    results = st.session_state['search_results']
                    if results is not None and 'similarity_score' in results.columns:
                        all_df = all_df.merge(results[['patent_id','similarity_score']], on='patent_id', how='left')

                    color_col, color_map = None, None
                    if color_by == 'è‡ªç¤¾/å€™è£œã®åŒºåˆ¥' and 'ç¨®åˆ¥' in all_df.columns:
                        color_col = 'ç¨®åˆ¥'
                        color_map = {'è‡ªç¤¾ç‰¹è¨±':'#f39c12','å€™è£œç‰¹è¨±':'#3498db'}
                    elif color_by == 'labelï¼ˆæ­£è§£/ãƒã‚¤ã‚ºï¼‰' and 'label' in all_df.columns:
                        all_df['label_str'] = all_df['label'].apply(
                            lambda x: 'æ­£è§£(1)' if x==1 else ('ãƒã‚¤ã‚º(0)' if x==0 else 'æœªãƒ©ãƒ™ãƒ«'))
                        color_col = 'label_str'
                        color_map = {'æ­£è§£(1)':'#2ecc71','ãƒã‚¤ã‚º(0)':'#e74c3c','æœªãƒ©ãƒ™ãƒ«':'#95a5a6'}
                    elif color_by == 'é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢' and 'similarity_score' in all_df.columns:
                        color_col = 'similarity_score'

                    hover = ['patent_id','title']
                    for c in ['label','similarity_score','ç¨®åˆ¥']:
                        if c in all_df.columns: hover.append(c)

                    fig = px.scatter(all_df, x='x', y='y',
                        color=color_col,
                        color_discrete_map=color_map if isinstance(color_map,dict) else None,
                        color_continuous_scale='RdYlGn' if color_col=='similarity_score' else None,
                        hover_data=hover,
                        text='patent_id' if show_labels else None,
                        symbol='ç¨®åˆ¥' if 'ç¨®åˆ¥' in all_df.columns else None,
                        symbol_map={'è‡ªç¤¾ç‰¹è¨±':'star','å€™è£œç‰¹è¨±':'circle'},
                        title=f"ç‰¹è¨±æ–‡æ›¸æ•£å¸ƒå›³ï¼ˆ{dim_method}ï¼‰  â˜…=è‡ªç¤¾ç‰¹è¨±  â—=å€™è£œç‰¹è¨±",
                        labels={'x':f'{dim_method}æˆåˆ†1','y':f'{dim_method}æˆåˆ†2'})
                    if show_labels: fig.update_traces(textposition='top center', textfont_size=8)
                    fig.update_layout(height=600)
                    st.plotly_chart(fig, use_container_width=True)
                    st.caption("è‡ªç¤¾ç‰¹è¨±(â˜…)å‘¨å›²ã®å€™è£œç‰¹è¨±(â—)ã»ã©ã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹ã«æ³¨æ„ãŒå¿…è¦ã§ã™ã€‚")
                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
                    st.code(traceback.format_exc())

    st.divider()
    results = st.session_state['search_results']
    if results is not None and 'similarity_score' in results.columns:
        st.subheader("é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢åˆ†å¸ƒ")
        fig_h = px.histogram(results, x='similarity_score',
            color='label' if 'label' in results.columns else None,
            color_discrete_map={1:'#2ecc71',0:'#e74c3c'},
            title="é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ", nbins=20, barmode='overlay', opacity=0.7)
        st.plotly_chart(fig_h, use_container_width=True)

    vec = st.session_state['vectorizer']
    if vec is not None and hasattr(vec,'get_top_features') and not cp.empty:
        st.divider()
        st.subheader("è‡ªç¤¾ç‰¹è¨±ã®é‡è¦èªï¼ˆTF-IDFï¼‰")
        sel_q = st.selectbox("ç‰¹è¨±ã‚’é¸æŠ", cp['patent_id'].tolist(), key='feat_q')
        q_row = cp[cp['patent_id']==sel_q].iloc[0]
        prep = st.session_state['preprocessor'] or get_preprocessor()
        q_text = prep.preprocess_patent_sections(
            title=str(q_row.get('title','') or ''),
            abstract=str(q_row.get('abstract','') or ''),
            claims=str(q_row.get('claims','') or ''),
            description=str(q_row.get('description','') or ''),
        )
        try:
            feats = vec.get_top_features(q_text, top_n=30)
            if feats:
                fd = pd.DataFrame(feats, columns=['èª','TF-IDFã‚¹ã‚³ã‚¢'])
                fig_f = px.bar(fd, x='TF-IDFã‚¹ã‚³ã‚¢', y='èª', orientation='h',
                               color='TF-IDFã‚¹ã‚³ã‚¢', color_continuous_scale='Blues',
                               title=f"{sel_q} ã®é‡è¦èª Top30")
                fig_f.update_layout(yaxis={'categoryorder':'total ascending'}, height=500)
                st.plotly_chart(fig_f, use_container_width=True)
        except Exception:
            st.caption("TF-IDFæ‰‹æ³•ã®ã¿å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TAB 6: å°‚é–€ç”¨èªè§£èª¬
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab6:
    st.header("ğŸ“– å°‚é–€ç”¨èªè§£èª¬")
    st.caption("æœ¬ã‚·ã‚¹ãƒ†ãƒ ã§ä½¿ç”¨ã—ã¦ã„ã‚‹æŠ€è¡“ç”¨èªã‚’ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«è§£èª¬ã—ã¾ã™ã€‚")

    term_tab1, term_tab2, term_tab3, term_tab4 = st.tabs([
        "ğŸ“ ãƒ™ã‚¯ãƒˆãƒ«åŒ–æ‰‹æ³•",
        "ğŸ¤– æ©Ÿæ¢°å­¦ç¿’ãƒ»åˆ†é¡",
        "ğŸ“Š å¯è¦–åŒ–ãƒ»é¡ä¼¼åº¦",
        "ğŸ”¬ ç‰¹è¨±èª¿æŸ»",
    ])

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ãƒ™ã‚¯ãƒˆãƒ«åŒ–æ‰‹æ³•
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with term_tab1:
        st.subheader("ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã¨ã¯")
        st.markdown("""
æ–‡ç« ï¼ˆãƒ†ã‚­ã‚¹ãƒˆï¼‰ã‚’ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãŒå‡¦ç†ã§ãã‚‹ **æ•°å€¤ã®ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆæ•°å€¤ã®é…åˆ—ï¼‰** ã«å¤‰æ›ã™ã‚‹æŠ€è¡“ã§ã™ã€‚
ç‰¹è¨±æ–‡æ›¸ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã™ã‚‹ã“ã¨ã§ã€æ–‡æ›¸é–“ã®é¡ä¼¼åº¦ã‚’æ•°å€¤ã¨ã—ã¦è¨ˆç®—ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚
        """)

        with st.expander("ğŸ“Œ BoWï¼ˆBag-of-Wordsï¼‰â€• æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªæ‰‹æ³•", expanded=True):
            col1, col2 = st.columns([3,2])
            with col1:
                st.markdown("""
**æ¦‚å¿µ:** æ–‡æ›¸ä¸­ã®å˜èªã® **å‡ºç¾å›æ•°** ã‚’æ•°ãˆã¦ãƒ™ã‚¯ãƒˆãƒ«ã«ã™ã‚‹

**ä¾‹:**
- æ–‡æ›¸A:ã€Œã‚¬ã‚¹ãƒãƒªã‚¢ ãƒ•ã‚£ãƒ«ãƒ  è£½é€  ã‚¬ã‚¹ãƒãƒªã‚¢ã€
- BoWãƒ™ã‚¯ãƒˆãƒ«:ã€Œã‚¬ã‚¹ãƒãƒªã‚¢=2, ãƒ•ã‚£ãƒ«ãƒ =1, è£½é€ =1ã€

**ç‰¹å¾´:**
- âœ… ã‚·ãƒ³ãƒ—ãƒ«ã§é«˜é€Ÿ
- âœ… ç›´æ„Ÿçš„ã«ç†è§£ã—ã‚„ã™ã„
- âŒ å˜èªã®é †åºã‚’ç„¡è¦–ã™ã‚‹
- âŒ ã€Œè£½é€ **ã—ãªã„**ã€ã¨ã€Œè£½é€ **ã™ã‚‹**ã€ã‚’åŒºåˆ¥ã§ããªã„
- âŒ ã‚ˆãä½¿ã‚ã‚Œã‚‹å˜èªï¼ˆåŠ©è©ç­‰ï¼‰ãŒå¤§ããªå€¤ã«ãªã‚Šã™ãã‚‹
                """)
            with col2:
                st.markdown("**ã‚¤ãƒ¡ãƒ¼ã‚¸:**")
                bow_data = {'å˜èª':['ã‚¬ã‚¹ãƒãƒªã‚¢','ãƒ•ã‚£ãƒ«ãƒ ','è£½é€ ','ãƒãƒªãƒ“ãƒ‹ãƒ«ã‚¢ãƒ«ã‚³ãƒ¼ãƒ«'],
                            'æ–‡æ›¸A':[2,1,1,0],'æ–‡æ›¸B':[1,2,0,1]}
                st.dataframe(pd.DataFrame(bow_data), hide_index=True)

        with st.expander("ğŸ“Œ TF-IDF â€• æœ¬ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ‰‹æ³•", expanded=True):
            col1, col2 = st.columns([3,2])
            with col1:
                st.markdown("""
**æ¦‚å¿µ:** å˜èªã®é‡è¦åº¦ã‚’2ã¤ã®æŒ‡æ¨™ã§è©•ä¾¡ã™ã‚‹

| æŒ‡æ¨™ | æ„å‘³ | è¨ˆç®—å¼ |
|------|------|--------|
| **TF** (Term Frequency) | æ–‡æ›¸å†…ã§ã®å˜èªã®å‡ºç¾é »åº¦ | å˜èªã®å‡ºç¾å›æ•° / å…¨å˜èªæ•° |
| **IDF** (Inverse Document Frequency) | å…¨æ–‡æ›¸ã«å…±é€šã—ã¦å‡ºç¾ã™ã‚‹å˜èªã‚’ä¸‹ã’ã‚‹ | log(å…¨æ–‡æ›¸æ•° / ãã®å˜èªã‚’å«ã‚€æ–‡æ›¸æ•°) |

**TF-IDF = TF Ã— IDF**
â†’ ã€Œãã®æ–‡æ›¸ã«ç‰¹å¾´çš„ãªå˜èªã€ã‚’é«˜ãè©•ä¾¡

**ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
""")
                st.table(pd.DataFrame({
                    'ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿': ['max_features', 'ngram_range', 'sublinear_tf'],
                    'æ„å‘³': ['ä½¿ç”¨ã™ã‚‹å˜èªã®æœ€å¤§æ•°ï¼ˆå¤§ãã„ã»ã©ç²¾åº¦â†‘ãƒ»é€Ÿåº¦â†“ï¼‰',
                             'é€£ç¶šã™ã‚‹å˜èªã®ã¾ã¨ã¾ã‚Šå˜ä½ï¼ˆ(1,1)=å˜èªã®ã¿ã€(1,2)=2èªã®çµ„ã‚‚ä½¿ç”¨ï¼‰',
                             'TFã®å€¤ã‚’å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ã«ã™ã‚‹ï¼ˆå¤§ããªå·®ã‚’ç·©å’Œï¼‰'],
                    'æœ¬ã‚·ã‚¹ãƒ†ãƒ ã®è¨­å®š': ['10,000ï¼ˆèª¿æ•´å¯ï¼‰', '(1,2)', 'True'],
                }))
            with col2:
                st.markdown("**TF-IDFã®ã‚¤ãƒ¡ãƒ¼ã‚¸:**")
                st.markdown("""
```
ã€Œã‚¬ã‚¹ãƒãƒªã‚¢ã€
â†’ TF=é«˜ï¼ˆã“ã®æ–‡æ›¸ã«å¤šã„ï¼‰
â†’ IDF=é«˜ï¼ˆç‰¹è¨±æ–‡æ›¸å…¨ä½“ã§ã¯çã—ã„ï¼‰
â†’ TF-IDF=é«˜ âœ… é‡è¦èª

ã€Œã™ã‚‹ã€
â†’ TF=é«˜ï¼ˆã“ã®æ–‡æ›¸ã«å¤šã„ï¼‰
â†’ IDF=ä½ï¼ˆå…¨æ–‡æ›¸ã«å‡ºã¦ãã‚‹ï¼‰
â†’ TF-IDF=ä½ âŒ é‡è¦ã§ãªã„
```
                """)

        with st.expander("ğŸ“Œ word2vec â€• å˜èªã®æ„å‘³ã‚’ãƒ™ã‚¯ãƒˆãƒ«ã§è¡¨ç¾"):
            st.markdown("""
**æ¦‚å¿µ:** å˜èªã‚’ **æ„å‘³çš„ã«è¿‘ã„å˜èªãŒãƒ™ã‚¯ãƒˆãƒ«ç©ºé–“ã§è¿‘ããªã‚‹** ã‚ˆã†ã«å­¦ç¿’ã™ã‚‹

- ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§å¤§é‡ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å˜èªã®ã€Œæ–‡è„ˆã€ã‚’å­¦ç¿’
- ä¾‹: ã€Œãƒãƒªã‚¨ãƒãƒ¬ãƒ³ã€ã¨ã€Œãƒãƒªãƒ—ãƒ­ãƒ”ãƒ¬ãƒ³ã€ã¯æ„å‘³ãŒä¼¼ã¦ã„ã‚‹ã®ã§ãƒ™ã‚¯ãƒˆãƒ«ãŒè¿‘ããªã‚‹

**æ–‡æ›¸ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼ˆãƒ—ãƒ¼ãƒªãƒ³ã‚°ï¼‰:**
- æ–‡æ›¸å†…ã®å…¨å˜èªã®ãƒ™ã‚¯ãƒˆãƒ«ã® **å¹³å‡ï¼ˆaverage poolingï¼‰** ã‚„ **æœ€å¤§å€¤ï¼ˆmax poolingï¼‰** ã‚’å–ã‚‹

**ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | æ„å‘³ | æ¨å¥¨å€¤ |
|-----------|------|--------|
| `vector_size` | å˜èªãƒ™ã‚¯ãƒˆãƒ«ã®æ¬¡å…ƒæ•° | 100ã€œ300 |
| `window` | æ–‡è„ˆã¨ã—ã¦è€ƒæ…®ã™ã‚‹å‰å¾Œã®å˜èªæ•° | 5ã€œ10 |
| `min_count` | ã“ã®å›æ•°ä»¥ä¸‹ã®å˜èªã¯ç„¡è¦– | 2ã€œ5 |
| `epochs` | å­¦ç¿’ã®ç¹°ã‚Šè¿”ã—å›æ•° | 10ã€œ100 |
            """)

        with st.expander("ğŸ“Œ doc2vec â€• æ–‡æ›¸å…¨ä½“ã‚’ãƒ™ã‚¯ãƒˆãƒ«ã§è¡¨ç¾ï¼ˆè«–æ–‡ã®ä¸»è¦æ‰‹æ³•ï¼‰"):
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("""
**æ¦‚å¿µ:** word2vecã‚’æ‹¡å¼µã—ã€æ–‡æ›¸ï¼ˆãƒ‘ãƒ©ã‚°ãƒ©ãƒ•ï¼‰å…¨ä½“ã‚’ãƒ™ã‚¯ãƒˆãƒ«ã§è¡¨ç¾ã™ã‚‹
è«–æ–‡ã§æœ€ã‚‚åŠ¹æœãŒã‚ã£ãŸæ‰‹æ³•ã¨ã—ã¦å ±å‘Šã•ã‚Œã¦ã„ã‚‹ã€‚

**2ã¤ã®ãƒ¢ãƒ¼ãƒ‰:**

**PV-DBOWï¼ˆdm=0ï¼‰**
- æ–‡æ›¸ãƒ™ã‚¯ãƒˆãƒ«ã‹ã‚‰æ–‡æ›¸å†…ã®å˜èªã‚’äºˆæ¸¬ã™ã‚‹ãƒ¢ãƒ‡ãƒ«
- ã‚·ãƒ³ãƒ—ãƒ«ã§é«˜é€Ÿ
- è«–æ–‡ã§ã¯ã“ã¡ã‚‰ã‚’ä¸»ã«ä½¿ç”¨

**PV-DMï¼ˆdm=1ï¼‰**
- æ–‡æ›¸ãƒ™ã‚¯ãƒˆãƒ«ï¼‹å‰å¾Œã®å˜èªã‹ã‚‰æ¬¡ã®å˜èªã‚’äºˆæ¸¬
- ã‚ˆã‚Šç²¾ç·»ã ãŒè¨ˆç®—ãŒé‡ã„

**ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | æ„å‘³ | æ¨å¥¨å€¤ |
|-----------|------|--------|
| `vector_size` | æ–‡æ›¸ãƒ™ã‚¯ãƒˆãƒ«ã®æ¬¡å…ƒæ•° | **200**ï¼ˆè«–æ–‡å€¤ï¼‰ |
| `epochs` | å­¦ç¿’å›æ•° | **100**ï¼ˆè«–æ–‡å€¤ï¼‰|
| `window` | æ–‡è„ˆçª“ã‚µã‚¤ã‚º | 5ã€œ10 |
| `min_count` | æœ€å°å‡ºç¾å›æ•° | 2 |
                """)
            with col2:
                st.markdown("""
**å­¦ç¿’ã®ä»•çµ„ã¿ï¼ˆPV-DBOWï¼‰:**
```
æ–‡æ›¸ã‚¿ã‚°ï¼ˆç‰¹è¨±ç•ªå·ï¼‰
       â†“
  [æ–‡æ›¸ãƒ™ã‚¯ãƒˆãƒ«]
       â†“
  å˜èªã‚’äºˆæ¸¬ â†’ èª¤å·®ã‚’é€†ä¼æ’­
       â†“
  ãƒ™ã‚¯ãƒˆãƒ«ã‚’æ›´æ–°
```
**æ¨è«–ï¼ˆæ–°æ–‡æ›¸ã¸ã®ãƒ™ã‚¯ãƒˆãƒ«å‰²ã‚Šå½“ã¦ï¼‰:**
```
æ–°ã—ã„æ–‡æ›¸
       â†“
  å­¦ç¿’æ¸ˆã¿èªå½™ã§æ¨è«–
  (infer_vector)
       â†“
  50ã€œ100å›ç¹°ã‚Šè¿”ã—ã¦åæŸ
       â†“
  æ–‡æ›¸ãƒ™ã‚¯ãƒˆãƒ«
```
                """)

        with st.expander("ğŸ“Œ LSAï¼ˆæ½œåœ¨æ„å‘³è§£æï¼‰â€• TF-IDFã®æ¬¡å…ƒå‰Šæ¸›ç‰ˆ"):
            st.markdown("""
**æ¦‚å¿µ:** TF-IDFã§å¾—ãŸé«˜æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«ï¼ˆæ•°ä¸‡æ¬¡å…ƒï¼‰ã‚’ SVDï¼ˆç‰¹ç•°å€¤åˆ†è§£ï¼‰ã§ä½æ¬¡å…ƒã«åœ§ç¸®ã™ã‚‹

**åŠ¹æœ:**
- è¨ˆç®—ã‚’é«˜é€ŸåŒ–
- ã€Œé…¸åŒ–ã‚±ã‚¤ç´ ã€ã¨ã€ŒSiOâ‚‚ã€ã®ã‚ˆã†ãªåŒç¾©èªã®é–¢ä¿‚ã‚’æ‰ãˆã‚„ã™ããªã‚‹
- éå­¦ç¿’ã‚’æŠ‘åˆ¶

**ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | æ„å‘³ | æ¨å¥¨å€¤ |
|-----------|------|--------|
| `n_components` | å‰Šæ¸›å¾Œã®æ¬¡å…ƒæ•° | 100ã€œ300 |

**TF-IDF + LSA = TF-IDF LSAï¼ˆæœ¬ã‚·ã‚¹ãƒ†ãƒ ã®ã€ŒTF-IDF + LSAã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰**
            """)

        with st.expander("ğŸ“Œ SCDVï¼ˆSparse Composite Document Vectorsï¼‰"):
            st.markdown("""
**æ¦‚å¿µ:** word2vec Ã— K-means ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚° Ã— ã‚¹ãƒ‘ãƒ¼ã‚¹åŒ– ã‚’çµ„ã¿åˆã‚ã›ãŸé«˜ç²¾åº¦ãªæ–‡æ›¸ãƒ™ã‚¯ãƒˆãƒ«åŒ–æ‰‹æ³•

**æ‰‹é †:**
1. å…¨å˜èªã® word2vec ãƒ™ã‚¯ãƒˆãƒ«ã‚’å­¦ç¿’
2. K-means ã§ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ï¼ˆæ„å‘³ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼‰
3. å„å˜èªã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ¥ã«é‡ã¿ä»˜ã‘ã—ã¦åˆæˆ
4. ã‚¹ãƒ‘ãƒ¼ã‚¹åŒ–ï¼ˆå°ã•ã„å€¤ã‚’0ã«ï¼‰

**ç‰¹å¾´:**
- âœ… word2vec ã®æ„å‘³æƒ…å ± + TF-IDF ã®é‡è¦åº¦ã‚’ä¸¡ç«‹
- âœ… è«–æ–‡ã§ã‚‚å¯è¦–åŒ–ã§è‰¯å¥½ãªã‚¹ã‚³ã‚¢ã‚’ç¢ºèªï¼ˆscore=0.756ï¼‰
- âŒ è¨ˆç®—ã‚³ã‚¹ãƒˆãŒæ¯”è¼ƒçš„é«˜ã„
            """)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # æ©Ÿæ¢°å­¦ç¿’ãƒ»åˆ†é¡
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with term_tab2:
        st.subheader("æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹é©åˆåˆ¤å®š")
        st.markdown("""
ç‰¹è¨±æ–‡æ›¸ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ãŸå¾Œã€**æ•™å¸«ã‚ã‚Šæ©Ÿæ¢°å­¦ç¿’** ã§ãã®æ–‡æ›¸ãŒã€Œé–¢é€£ï¼ˆæ­£è§£ï¼‰ã€ã‹
ã€Œç„¡é–¢ä¿‚ï¼ˆãƒã‚¤ã‚ºï¼‰ã€ã‹ã‚’è‡ªå‹•åˆ¤å®šã—ã¾ã™ã€‚
        """)

        with st.expander("ğŸ“Œ æ•™å¸«ã‚ã‚Šå­¦ç¿’ / æ•™å¸«ãªã—å­¦ç¿’", expanded=True):
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("""
**æ•™å¸«ã‚ã‚Šå­¦ç¿’ï¼ˆæœ¬ã‚·ã‚¹ãƒ†ãƒ ã®ä¸»ãªæ‰‹æ³•ï¼‰**
- æ­£è§£ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’
- ä¾‹: ã€Œã“ã®ç‰¹è¨±ã¯é–¢é€£(1)ã€ã€Œã“ã®ç‰¹è¨±ã¯ç„¡é–¢ä¿‚(0)ã€ã®ãƒ©ãƒ™ãƒ«ã‚’ä¸ãˆã¦ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’
- â†’ æ–°ã—ã„ç‰¹è¨±ã«å¯¾ã—ã¦è‡ªå‹•ã§é–¢é€£åº¦ã‚’äºˆæ¸¬ã§ãã‚‹
                """)
            with col2:
                st.markdown("""
**æ•™å¸«ãªã—å­¦ç¿’**
- ãƒ©ãƒ™ãƒ«ãªã—ã§æ–‡æ›¸ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼ˆã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ï¼‰
- ä¾‹: ä¼¼ãŸç‰¹è¨±ã‚’è‡ªå‹•ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°ã€æ¬¡å…ƒå‰Šæ¸›ã«ã‚ˆã‚‹å¯è¦–åŒ–
- â†’ æœ¬ã‚·ã‚¹ãƒ†ãƒ ã®ã€Œæ•£å¸ƒå›³ã€ãŒã“ã‚Œã«ç›¸å½“
                """)

        with st.expander("ğŸ“Œ è©•ä¾¡æŒ‡æ¨™: ç²¾åº¦ãƒ»å†ç¾ç‡ãƒ»F1ã‚¹ã‚³ã‚¢", expanded=True):
            col1, col2 = st.columns([3,2])
            with col1:
                st.markdown("""
**ã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹èª¿æŸ»ã«ãŠã‘ã‚‹é‡è¦æ€§:**
- èª¿æŸ»æ¼ã‚Œï¼ˆè¦‹é€ƒã—ï¼‰ã¯è‡´å‘½çš„ãªãƒªã‚¹ã‚¯ â†’ **å†ç¾ç‡** ã‚’é‡è¦–
- ãŸã ã—ç²¾åº¦ã‚‚ä½ã™ãã‚‹ã¨ç¢ºèªä½œæ¥­ãŒå¢—ãˆã‚‹ â†’ ãƒãƒ©ãƒ³ã‚¹ãŒå¿…è¦

**æŒ‡æ¨™ã®æ„å‘³:**

| æŒ‡æ¨™ | è¨ˆç®—å¼ | ã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹ã§ã®æ„å‘³ |
|------|--------|---------------------|
| **ç²¾åº¦ (Precision)** | TP / (TP + FP) | é–¢é€£ã¨äºˆæ¸¬ã—ãŸä¸­ã§å®Ÿéš›ã«é–¢é€£ã™ã‚‹å‰²åˆ |
| **å†ç¾ç‡ (Recall)** | TP / (TP + FN) | å®Ÿéš›ã®é–¢é€£ç‰¹è¨±ã®ã†ã¡æ­£ã—ãæ¤œå‡ºã§ããŸå‰²åˆ |
| **F1ã‚¹ã‚³ã‚¢** | 2Ã—PÃ—R / (P+R) | ç²¾åº¦ã¨å†ç¾ç‡ã®èª¿å’Œå¹³å‡ |

TP=æ­£ã—ãã€Œé–¢é€£ã€ã¨äºˆæ¸¬, FP=èª¤ã£ã¦ã€Œé–¢é€£ã€ã¨äºˆæ¸¬, FN=è¦‹é€ƒã—ãŸã€Œé–¢é€£ã€
                """)
            with col2:
                st.markdown("**æ··åŒè¡Œåˆ—ï¼ˆConfusion Matrixï¼‰:**")
                cm_data = pd.DataFrame(
                    [['TPï¼ˆæ­£ã—ãæ¤œå‡ºï¼‰','FNï¼ˆè¦‹é€ƒã—ï¼ï¼‰'],
                     ['FPï¼ˆèª¤æ¤œå‡ºï¼‰','TNï¼ˆæ­£ã—ãé™¤å¤–ï¼‰']],
                    index=['å®Ÿéš›: é–¢é€£(1)','å®Ÿéš›: ç„¡é–¢ä¿‚(0)'],
                    columns=['äºˆæ¸¬: é–¢é€£(1)','äºˆæ¸¬: ç„¡é–¢ä¿‚(0)'],
                )
                st.dataframe(cm_data)
                st.markdown("""
ã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹èª¿æŸ»ã§ã¯ **FNï¼ˆè¦‹é€ƒã—ï¼‰ã‚’æœ€å°åŒ–** ã™ã‚‹ã“ã¨ãŒæœ€é‡è¦ã€‚
â†’ å†ç¾ç‡ãŒé«˜ã„ãƒ¢ãƒ‡ãƒ«ã‚’é¸ã¶
                """)

        with st.expander("ğŸ“Œ äº¤å·®æ¤œè¨¼ï¼ˆCross-Validationï¼‰"):
            st.markdown("""
**æ¦‚å¿µ:** ãƒ‡ãƒ¼ã‚¿ã‚’è¤‡æ•°å›ã«åˆ†ã‘ã¦å­¦ç¿’ãƒ»è©•ä¾¡ã‚’ç¹°ã‚Šè¿”ã—ã€ãƒ¢ãƒ‡ãƒ«ã®æ±åŒ–æ€§èƒ½ã‚’ç¢ºèªã™ã‚‹æ‰‹æ³•

**Kåˆ†å‰²äº¤å·®æ¤œè¨¼ã®æµã‚Œï¼ˆK=5ã®å ´åˆï¼‰:**
```
ãƒ‡ãƒ¼ã‚¿å…¨ä½“ = [A][B][C][D][E]

è©¦è¡Œ1: å­¦ç¿’=[B][C][D][E], ãƒ†ã‚¹ãƒˆ=[A]
è©¦è¡Œ2: å­¦ç¿’=[A][C][D][E], ãƒ†ã‚¹ãƒˆ=[B]
è©¦è¡Œ3: å­¦ç¿’=[A][B][D][E], ãƒ†ã‚¹ãƒˆ=[C]
è©¦è¡Œ4: å­¦ç¿’=[A][B][C][E], ãƒ†ã‚¹ãƒˆ=[D]
è©¦è¡Œ5: å­¦ç¿’=[A][B][C][D], ãƒ†ã‚¹ãƒˆ=[E]

æœ€çµ‚ã‚¹ã‚³ã‚¢ = 5å›ã®ã‚¹ã‚³ã‚¢ã®å¹³å‡Â±æ¨™æº–åå·®
```
**ãªãœé‡è¦ï¼Ÿ:** ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹å¶ç„¶ã®éå­¦ç¿’ã‚’é˜²ãã€ãƒ¢ãƒ‡ãƒ«ã®çœŸã®æ€§èƒ½ã‚’æ¨å®šã§ãã‚‹
            """)

        with st.expander("ğŸ“Œ éå­¦ç¿’ï¼ˆOverfittingï¼‰"):
            st.markdown("""
**æ¦‚å¿µ:** ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«éåº¦ã«é©åˆã—ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦æ€§èƒ½ãŒä¸‹ãŒã‚‹ç¾è±¡

```
å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æ­£è§£ç‡: 100%   â† ä¸¸æš—è¨˜ã—ã¦ã—ã¾ã£ãŸçŠ¶æ…‹
ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ­£è§£ç‡: 60%  â† æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã«ã¯å¼±ã„
```

**å¯¾ç­–:**
- ãƒ‡ãƒ¼ã‚¿é‡ã‚’å¢—ã‚„ã™ï¼ˆç‰¹è¨±DBä»¶æ•°ã‚’å¢—ã‚„ã™ï¼‰
- äº¤å·®æ¤œè¨¼ã§ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã™ã‚‹
- æ­£è¦åŒ–ï¼ˆRegularizationï¼‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´
- ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆï¼ˆãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã®å ´åˆï¼‰
            """)

        with st.expander("ğŸ“Œ å„åˆ†é¡ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ç‰¹å¾´ï¼ˆè«–æ–‡: 13ç¨®é¡æ¯”è¼ƒï¼‰"):
            alg_data = {
                'ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ': [
                    'ã‚¨ã‚¤ãƒ€ãƒ–ãƒ¼ã‚¹ãƒˆï¼ˆAdaBoostï¼‰',
                    'ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ',
                    'SVMï¼ˆã‚µãƒãƒ¼ãƒˆãƒ™ã‚¯ã‚¿ãƒ¼ãƒã‚·ãƒ³ï¼‰',
                    'ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°',
                    'ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆï¼ˆMLPï¼‰',
                    'ãƒã‚®ãƒ³ã‚°',
                    'å‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°',
                    'kè¿‘å‚æ³•ï¼ˆk-NNï¼‰',
                    'ãƒŠã‚¤ãƒ¼ãƒ–ãƒ™ã‚¤ã‚º',
                    'æ±ºå®šæœ¨',
                ],
                'è«–æ–‡è©•ä¾¡': ['â— æœ€è‰¯','â— æœ€è‰¯','â—‹','â—‹','â—‹','â–³','â—‹','â–³','â–³','â–³'],
                'ç‰¹å¾´': [
                    'å¼±ã„åˆ†é¡å™¨ã‚’é€æ¬¡å¼·åŒ–ã€‚ç²¾åº¦ãŒé«˜ã„',
                    'å¤šæ•°ã®æ±ºå®šæœ¨ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã€‚éå­¦ç¿’ã—ã«ãã„',
                    'é«˜æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã«å¼·ã„ã€‚ãƒ†ã‚­ã‚¹ãƒˆåˆ†é¡ã«æœ‰åŠ¹',
                    'ã‚·ãƒ³ãƒ—ãƒ«ã§è§£é‡ˆã—ã‚„ã™ã„ç·šå½¢ãƒ¢ãƒ‡ãƒ«',
                    'æ·±å±¤å­¦ç¿’ã€‚å¤§é‡ãƒ‡ãƒ¼ã‚¿ã§çœŸä¾¡ã‚’ç™ºæ®',
                    'ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹ä¸¦åˆ—ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«',
                    'æ±ºå®šæœ¨ã‚’é€æ¬¡æ”¹å–„ã€‚XGBoostã®åŸå‹',
                    'è¿‘å‚kä»¶ã®å¤šæ•°æ±ºã€‚å®Ÿè£…ãŒã‚·ãƒ³ãƒ—ãƒ«',
                    'ç‹¬ç«‹æ€§ä»®å®šã®ãƒ™ã‚¤ã‚ºåˆ†é¡ã€‚ã‚¹ãƒ‘ãƒ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã§å®Ÿç¸¾',
                    'è§£é‡ˆã—ã‚„ã™ã„ãŒéå­¦ç¿’ã—ã‚„ã™ã„',
                ],
            }
            st.dataframe(pd.DataFrame(alg_data), hide_index=True, use_container_width=True)
            st.caption("è«–æ–‡ï¼ˆtokugikon 2018ï¼‰ã§ã¯ AdaBoostãƒ»ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆãŒæœ€è‰¯ã®çµæœã‚’ç¤ºã—ãŸã€‚")

        with st.expander("ğŸ“Œ AUC-ROC ã‚¹ã‚³ã‚¢"):
            st.markdown("""
**AUC-ROCï¼ˆArea Under the Curve - Receiver Operating Characteristicï¼‰**

- ãƒ¢ãƒ‡ãƒ«ã®åˆ†é¡æ€§èƒ½ã‚’ **é–¾å€¤ã«ä¾å­˜ã›ãš** ã«è©•ä¾¡ã™ã‚‹æŒ‡æ¨™
- ROCæ›²ç·š: é–¾å€¤ã‚’å¤‰ãˆãŸã¨ãã®ã€ŒçœŸé™½æ€§ç‡ï¼ˆå†ç¾ç‡ï¼‰ã€ã¨ã€Œå½é™½æ€§ç‡ã€ã®é–¢ä¿‚ã‚’ç¤ºã™æ›²ç·š
- **AUC = ROCæ›²ç·šã®ä¸‹ã®é¢ç©**

| AUCã®å€¤ | æ„å‘³ |
|---------|------|
| 1.0 | å®Œå…¨ãªåˆ†é¡ï¼ˆç†æƒ³ï¼‰ |
| 0.9ä»¥ä¸Š | éå¸¸ã«å„ªç§€ |
| 0.7ã€œ0.9 | è‰¯å¥½ |
| 0.5 | ãƒ©ãƒ³ãƒ€ãƒ ã¨åŒç­‰ï¼ˆæœ€æ‚ªï¼‰ |

ã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹èª¿æŸ»ã§ã¯ **AUCâ‰¥0.8** ã‚’ç›®æ¨™ã«ã™ã‚‹ã¨è‰¯ã„ã€‚
            """)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # å¯è¦–åŒ–ãƒ»é¡ä¼¼åº¦
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with term_tab3:
        st.subheader("é¡ä¼¼åº¦è¨ˆç®—ã¨å¯è¦–åŒ–ã®æ‰‹æ³•")

        with st.expander("ğŸ“Œ ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ â€• æœ¬ã‚·ã‚¹ãƒ†ãƒ ã®é¡ä¼¼åº¦æŒ‡æ¨™", expanded=True):
            col1, col2 = st.columns([3,2])
            with col1:
                st.markdown("""
**æ¦‚å¿µ:** 2ã¤ã®ãƒ™ã‚¯ãƒˆãƒ«ãŒ **åŒã˜æ–¹å‘ã‚’å‘ã„ã¦ã„ã‚‹ã‹** ã§é¡ä¼¼åº¦ã‚’æ¸¬ã‚‹

$$\\text{cosine similarity} = \\frac{\\vec{A} \\cdot \\vec{B}}{|\\vec{A}| \\times |\\vec{B}|}$$

**ç‰¹å¾´:**
- å€¤ã®ç¯„å›²: **-1 ã€œ 1**ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã®å ´åˆã¯ 0ã€œ1ï¼‰
- 1.0: å®Œå…¨ã«åŒã˜æ–¹å‘ï¼ˆéå¸¸ã«é¡ä¼¼ï¼‰
- 0.0: ç›´äº¤ï¼ˆç„¡é–¢ä¿‚ï¼‰
- -1.0: åå¯¾æ–¹å‘

**æ–‡æ›¸é‡ã«å½±éŸ¿ã•ã‚Œãªã„:**
- é•·ã„æ–‡æ›¸ã¨çŸ­ã„æ–‡æ›¸ã§ã‚‚å…¬å¹³ã«æ¯”è¼ƒã§ãã‚‹
- BoWç­‰ã§ã¯æ–‡æ›¸ã®é•·ã•ã§å˜èªé »åº¦ãŒå¤‰ã‚ã‚‹ãŒã€ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã¯æ­£è¦åŒ–ã•ã‚Œã¦ã„ã‚‹

**æœ¬ã‚·ã‚¹ãƒ†ãƒ ã§ã®ç›®å®‰:**
| ã‚¹ã‚³ã‚¢ | æ„å‘³ |
|--------|------|
| 0.7ä»¥ä¸Š | éå¸¸ã«é¡ä¼¼ï¼ˆè¦æ³¨æ„ï¼‰ |
| 0.5ã€œ0.7 | é¡ä¼¼ï¼ˆç¢ºèªæ¨å¥¨ï¼‰ |
| 0.3ã€œ0.5 | éƒ¨åˆ†çš„ã«é¡ä¼¼ |
| 0.3æœªæº€ | ã»ã¼ç„¡é–¢ä¿‚ |
                """)
            with col2:
                st.markdown("**ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã®ã‚¤ãƒ¡ãƒ¼ã‚¸:**")
                theta = np.linspace(0, np.pi/2, 100)
                fig_cos = go.Figure()
                fig_cos.add_trace(go.Scatter(
                    x=np.cos(theta), y=np.sin(theta),
                    mode='lines', name='å˜ä½å††', line=dict(color='gray', dash='dot')))
                # ãƒ™ã‚¯ãƒˆãƒ«A
                fig_cos.add_annotation(ax=0,ay=0,x=0.9,y=0.43,
                    xref='x',yref='y',axref='x',ayref='y',
                    showarrow=True,arrowhead=2,arrowcolor='blue',arrowwidth=2)
                fig_cos.add_annotation(x=0.95,y=0.48,text='Aï¼ˆè‡ªç¤¾ç‰¹è¨±ï¼‰',
                    showarrow=False,font=dict(color='blue'))
                # ãƒ™ã‚¯ãƒˆãƒ«Bï¼ˆé¡ä¼¼ï¼‰
                fig_cos.add_annotation(ax=0,ay=0,x=0.85,y=0.53,
                    xref='x',yref='y',axref='x',ayref='y',
                    showarrow=True,arrowhead=2,arrowcolor='green',arrowwidth=2)
                fig_cos.add_annotation(x=0.88,y=0.6,text='Bï¼ˆé¡ä¼¼: 0.98ï¼‰',
                    showarrow=False,font=dict(color='green'))
                # ãƒ™ã‚¯ãƒˆãƒ«Cï¼ˆç„¡é–¢ä¿‚ï¼‰
                fig_cos.add_annotation(ax=0,ay=0,x=0.2,y=0.98,
                    xref='x',yref='y',axref='x',ayref='y',
                    showarrow=True,arrowhead=2,arrowcolor='red',arrowwidth=2)
                fig_cos.add_annotation(x=0.25,y=1.05,text='Cï¼ˆç„¡é–¢ä¿‚: 0.25ï¼‰',
                    showarrow=False,font=dict(color='red'))
                fig_cos.update_layout(height=280, showlegend=False,
                    xaxis=dict(range=[-0.1,1.2],title=''),
                    yaxis=dict(range=[-0.1,1.2],title=''),
                    margin=dict(l=0,r=0,t=10,b=0))
                st.plotly_chart(fig_cos, use_container_width=True)

        with st.expander("ğŸ“Œ SVDï¼ˆç‰¹ç•°å€¤åˆ†è§£ï¼‰ã«ã‚ˆã‚‹æ¬¡å…ƒå‰Šæ¸›", expanded=True):
            st.markdown("""
**æ¦‚å¿µ:** é«˜æ¬¡å…ƒã®ç‰¹è¨±ãƒ™ã‚¯ãƒˆãƒ«ã‚’2æ¬¡å…ƒã¾ãŸã¯3æ¬¡å…ƒã«åœ§ç¸®ã—ã¦å¯è¦–åŒ–ã™ã‚‹

$$\\text{é«˜æ¬¡å…ƒè¡Œåˆ—} \\approx U \\cdot \\Sigma \\cdot V^T$$

**æœ¬ã‚·ã‚¹ãƒ†ãƒ ã§ã®ç”¨é€”:**
1. **æ•£å¸ƒå›³ã®ç”Ÿæˆ**: 10,000æ¬¡å…ƒã®TF-IDFãƒ™ã‚¯ãƒˆãƒ«ã‚’2æ¬¡å…ƒã«åœ§ç¸®
2. **LSAï¼ˆTF-IDF + LSAï¼‰**: 100ã€œ300æ¬¡å…ƒã«åœ§ç¸®ã—ã¦é¡ä¼¼åº¦è¨ˆç®—ã®ç²¾åº¦ã‚’ä¸Šã’ã‚‹

**æ¬¡å…ƒå‰Šæ¸›ã®æ¯”å–©ï¼ˆè«–æ–‡ã‚ˆã‚Šï¼‰:**
> åœ°çƒï¼ˆ3æ¬¡å…ƒã®çƒï¼‰ã‚’åœ°å›³ï¼ˆ2æ¬¡å…ƒã®å¹³é¢ï¼‰ã«æŠ•å½±ã™ã‚‹ã¨ãã€å¿…ãšæ­ªã¿ãŒç”Ÿã˜ã‚‹ã€‚
> SVDãƒ»PCAã‚‚åŒæ§˜ã«é«˜æ¬¡å…ƒã®æƒ…å ±ã‚’2æ¬¡å…ƒã«åœ§ç¸®ã™ã‚‹éš›ã«æƒ…å ±ãŒå¤±ã‚ã‚Œã‚‹ã€‚
> åœ°å›³ã®å›³æ³•ï¼ˆãƒ¡ãƒ«ã‚«ãƒˆãƒ«ã€ãƒ¢ãƒ«ãƒ¯ã‚¤ãƒ‡ç­‰ï¼‰ã®ã‚ˆã†ã«ã€ç›®çš„ã«å¿œã˜ãŸæ‰‹æ³•ã‚’é¸ã¶ã“ã¨ãŒé‡è¦ã€‚

**ã‚°ãƒ©ãƒ•ã®èª­ã¿æ–¹:**
- è¿‘ãã«ã‚ã‚‹ç‚¹ = æ„å‘³çš„ã«é¡ä¼¼ã—ãŸç‰¹è¨±
- è‡ªç¤¾ç‰¹è¨±(â˜…)ã«è¿‘ã„å€™è£œç‰¹è¨±(â—) = ã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹ã«è¦æ³¨æ„
- åŒã˜è‰²ã®ç‚¹ãŒå›ºã¾ã£ã¦ã„ã‚‹ = æŠ€è¡“åˆ†é‡ãŒã‚ˆãåˆ†é¡ã§ãã¦ã„ã‚‹
            """)

        with st.expander("ğŸ“Œ PCAï¼ˆä¸»æˆåˆ†åˆ†æï¼‰"):
            st.markdown("""
**æ¦‚å¿µ:** ãƒ‡ãƒ¼ã‚¿ã®åˆ†æ•£ï¼ˆã°ã‚‰ã¤ãï¼‰ãŒæœ€å¤§ã«ãªã‚‹æ–¹å‘ã‚’ã€Œä¸»æˆåˆ†ã€ã¨ã—ã¦æ¬¡å…ƒå‰Šæ¸›ã™ã‚‹

**SVD ã¨ã®é•ã„:**
| | SVD (LSA) | PCA |
|--|-----------|-----|
| è¨ˆç®—å¯¾è±¡ | æ–‡æ›¸Ã—å˜èªã®è¡Œåˆ— | å…±åˆ†æ•£è¡Œåˆ— |
| è² ã®å€¤ | ã‚ã‚Š | ãªã—ï¼ˆæ¨™æº–åŒ–å¾Œã¯ã‚ã‚Šï¼‰ |
| å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ | âœ… å¾—æ„ | â–³ å¤§è¦æ¨¡ã¯é…ã„ |
| æœ¬ã‚·ã‚¹ãƒ†ãƒ ã®æ¨å¥¨ | âœ… TF-IDFã¨ç›¸æ€§ãŒè‰¯ã„ | å‚è€ƒç”¨ |
            """)

        with st.expander("ğŸ“Œ è¤‡æ•°ã‚¯ã‚¨ãƒªã®é›†ç´„æˆ¦ç•¥"):
            st.markdown("""
è‡ªç¤¾ç‰¹è¨±ãŒè¤‡æ•°ä»¶ã‚ã‚‹å ´åˆã€å„å€™è£œç‰¹è¨±ã®ã‚¹ã‚³ã‚¢ã‚’ã©ã†é›†ç´„ã™ã‚‹ã‹ã®æˆ¦ç•¥ã§ã™ã€‚

| æˆ¦ç•¥ | è¨ˆç®—å¼ | ç‰¹å¾´ | æ¨å¥¨ç”¨é€” |
|------|--------|------|---------|
| **æœ€å¤§ã‚¹ã‚³ã‚¢ï¼ˆmaxï¼‰** | `max(sim(è‡ªç¤¾i, å€™è£œj))` | 1ä»¶ã§ã‚‚é¡ä¼¼ã—ã¦ã„ã‚Œã°é«˜ã‚¹ã‚³ã‚¢ | **ã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹èª¿æŸ»ï¼ˆæ¨å¥¨ï¼‰** |
| **å¹³å‡ã‚¹ã‚³ã‚¢ï¼ˆmeanï¼‰** | `mean(sim(è‡ªç¤¾i, å€™è£œj))` | å…¨è‡ªç¤¾ç‰¹è¨±ã¸ã®å¹³å‡çš„ãªè¿‘ã• | æŠ€è¡“ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªåˆ†æ |
| **çµåˆãƒ™ã‚¯ãƒˆãƒ«ï¼ˆcombinedï¼‰** | `sim(mean(è‡ªç¤¾ãƒ™ã‚¯ãƒˆãƒ«), å€™è£œj)` | è‡ªç¤¾æŠ€è¡“ã®ã€Œé‡å¿ƒã€ã‹ã‚‰ã®è·é›¢ | æŠ€è¡“é ˜åŸŸã®ä¸­å¿ƒã‹ã‚‰ã®åˆ†æ |

**ã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹èª¿æŸ»ã§ã¯ã€Œæœ€å¤§ã‚¹ã‚³ã‚¢ã€ã‚’æ¨å¥¨:**
ä¾µå®³ãƒªã‚¹ã‚¯ã¯ã€Œã©ã‚Œã‹1ä»¶ã®è‡ªç¤¾ç‰¹è¨±ã«é¡ä¼¼ã—ã¦ã„ã‚Œã°ç™ºç”Ÿã™ã‚‹ã€ãŸã‚ã€æœ€å¤§å€¤ã§è©•ä¾¡ã™ã‚‹ã®ãŒæœ€ã‚‚å®‰å…¨å´ã®åˆ¤æ–­ã¨ãªã‚Šã¾ã™ã€‚
            """)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ç‰¹è¨±èª¿æŸ»
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with term_tab4:
        st.subheader("ç‰¹è¨±èª¿æŸ»ãƒ»ã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹èª¿æŸ»ã®åŸºç¤ç”¨èª")

        with st.expander("ğŸ“Œ ç‰¹è¨±ã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹èª¿æŸ»ï¼ˆFreedom-to-Operate: FTOèª¿æŸ»ï¼‰ã¨ã¯", expanded=True):
            st.markdown("""
**å®šç¾©:** æ–°è£½å“ãƒ»æ–°æŠ€è¡“ã® **è£½é€ ãƒ»è²©å£²ãƒ»ä½¿ç”¨ãŒä»–ç¤¾ã®æœ‰åŠ¹ç‰¹è¨±æ¨©ã‚’ä¾µå®³ã—ãªã„ã‹** ã‚’äº‹å‰ã«èª¿æŸ»ã™ã‚‹ã“ã¨

**ãªãœé‡è¦ã‹:**
- çŸ¥ã‚‰ãšã«ä»–ç¤¾ç‰¹è¨±ã‚’ä¾µå®³ã™ã‚‹ã¨æå®³è³ å„Ÿãƒ»è£½å“å›åã®ãƒªã‚¹ã‚¯
- ç‰¹ã«å¸‚å ´æŠ•å…¥å‰ã®èª¿æŸ»ãŒé‡è¦

**èª¿æŸ»ã®æµã‚Œï¼ˆæœ¬ã‚·ã‚¹ãƒ†ãƒ ã®ä½ç½®ã¥ã‘ï¼‰:**
```
â‘  èª¿æŸ»å¯¾è±¡ã®è£½å“ãƒ»æŠ€è¡“ã‚’ç‰¹å®š
â‘¡ é–¢é€£ã™ã‚‹ç‰¹è¨±ã‚’åé›†ï¼ˆå€™è£œç‰¹è¨±DBï¼‰
â‘¢ è‡ªç¤¾è£½å“ã¨ã®é¡ä¼¼åº¦ã‚’è©•ä¾¡  â† æœ¬ã‚·ã‚¹ãƒ†ãƒ ã®é¡ä¼¼åº¦æ¤œç´¢
â‘£ é‡è¦ç‰¹è¨±ã‚’é¸å®šãƒ»è©³ç´°åˆ†æ  â† æœ¬ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°
â‘¤ æ³•å¾‹å°‚é–€å®¶ï¼ˆå¼ç†å£«ï¼‰ã¨é€£æºã—ã¦æœ€çµ‚åˆ¤æ–­
```

**æ³¨æ„:** æœ¬ã‚·ã‚¹ãƒ†ãƒ ã®çµæœã¯ **å‚è€ƒæƒ…å ±** ã§ã™ã€‚æœ€çµ‚çš„ãªä¾µå®³åˆ¤æ–­ã¯å¼ç†å£«ãƒ»å¼è­·å£«ãŒè¡Œã†å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
            """)

        with st.expander("ğŸ“Œ SDIï¼ˆSelective Dissemination of Information: é¸æŠçš„æƒ…å ±é…ä¿¡ï¼‰"):
            st.markdown("""
**æ¦‚å¿µ:** äº‹å‰ã«å®šã‚ãŸæŠ€è¡“é ˜åŸŸï¼ˆã‚¹ã‚³ãƒ¼ãƒ—ï¼‰ã«é–¢é€£ã™ã‚‹æ–°ç€ç‰¹è¨±æƒ…å ±ã‚’è‡ªå‹•çš„ã«é¸æŠãƒ»æä¾›ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹

**SDIã¨ã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹èª¿æŸ»ã®é•ã„:**

| | SDI | ã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹èª¿æŸ» |
|--|-----|----------------|
| ç›®çš„ | ç«¶åˆæŠ€è¡“ã® **å‹•å‘ç›£è¦–** | ç‰¹å®šè£½å“ã® **ä¾µå®³ãƒªã‚¹ã‚¯è©•ä¾¡** |
| ã‚¿ã‚¤ãƒŸãƒ³ã‚° | ç¶™ç¶šçš„ãƒ»å®šæœŸçš„ | è£½å“é–‹ç™ºãƒ»ä¸Šå¸‚å‰ |
| ã‚¹ã‚³ãƒ¼ãƒ— | æ—¢å®šï¼ˆå¤‰ã‚ã‚Šã«ãã„ï¼‰ | è£½å“ä»•æ§˜ã«ä¾å­˜ |
| å¯¾è±¡ | æ–°ç€å…¬é–‹ç‰¹è¨± | æœ‰åŠ¹ç‰¹è¨±ï¼ˆå­˜ç¶šä¸­ï¼‰ |

**æœ¬è«–æ–‡ã§ã®SDIæ´»ç”¨:**
è‡ªç¤¾ã®æŠ€è¡“ã‚¹ã‚³ãƒ¼ãƒ—ã‚’å®šã‚ã€2ã‚¯ãƒ©ã‚¹åˆ†é¡ï¼ˆã‚·ã‚°ãƒŠãƒ«/ãƒã‚¤ã‚ºï¼‰ã§æ–°ç€ç‰¹è¨±ã‹ã‚‰é–¢é€£æ–‡æ›¸ã‚’è‡ªå‹•é¸åˆ¥ã™ã‚‹ã€‚
            """)

        with st.expander("ğŸ“Œ ç‰¹è¨±åˆ†é¡ã‚³ãƒ¼ãƒ‰ï¼ˆIPCãƒ»FIãƒ»Fã‚¿ãƒ¼ãƒ ï¼‰"):
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("""
**IPCï¼ˆInternational Patent Classificationï¼‰**
- å›½éš›ç‰¹è¨±åˆ†é¡ã€‚å…¨ä¸–ç•Œå…±é€š
- ä¾‹: `C08J 5/18`ï¼ˆãƒ—ãƒ©ã‚¹ãƒãƒƒã‚¯ãƒ•ã‚£ãƒ«ãƒ ã®è£½é€ ï¼‰
- ã‚»ã‚¯ã‚·ãƒ§ãƒ³(C) â†’ ã‚¯ãƒ©ã‚¹(08) â†’ ã‚µãƒ–ã‚¯ãƒ©ã‚¹(J) â†’ ã‚°ãƒ«ãƒ¼ãƒ—(5/18)

**FIï¼ˆFile Indexï¼‰**
- æ—¥æœ¬ç‰¹è¨±åºãŒ IPCã‚’ç´°åˆ†åŒ–ã—ãŸåˆ†é¡
- ä¾‹: `C08J 5/18 100`
- æ—¥æœ¬èªç‰¹è¨±ã®æ¤œç´¢ã«ç‰¹ã«æœ‰åŠ¹

**Fã‚¿ãƒ¼ãƒ ï¼ˆFile Forming Termï¼‰**
- æ—¥æœ¬ç‰¹è¨±åºç‹¬è‡ªã®å¤šé¢çš„åˆ†é¡
- æŠ€è¡“çš„è¦³ç‚¹ï¼ˆææ–™ãƒ»æ§‹é€ ãƒ»è£½æ³•ç­‰ï¼‰ã‚’è¤‡æ•°ã®è»¸ã§åˆ†é¡
- ä¾‹: `4F071AA01` (é«˜åˆ†å­ãƒ•ã‚£ãƒ«ãƒ ã®è£½é€ )
                """)
            with col2:
                st.markdown("""
**ç‰¹è¨±èª¿æŸ»ã§ã®æ´»ç”¨:**
- é¡ä¼¼åº¦æ¤œç´¢ã¨çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§èª¿æŸ»ç²¾åº¦ãŒå‘ä¸Š
- IPC/FIã§ã€Œé–¢é€£ã™ã‚‹æŠ€è¡“é ˜åŸŸã€ã‚’çµã‚Šè¾¼ã¿ â†’ å€™è£œç‰¹è¨±DB ã®ç¯„å›²ã‚’é™å®š
- è«–æ–‡ã§ã‚‚ã€ŒIPC,FI,Ftermã‚’ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨çµ„ã¿åˆã‚ã›ã¦ä½¿ã†ã“ã¨ãŒé‡è¦ã€ã¨è¨€åŠ

**æœ¬ã‚·ã‚¹ãƒ†ãƒ ã¸ã®çµ„ã¿è¾¼ã¿æ–¹:**
```
å€™è£œç‰¹è¨±DBã‚’ä½œæˆã™ã‚‹éš›ã«ã€
IPCãƒ»FIã§çµã‚Šè¾¼ã‚“ã æ¤œç´¢çµæœã‚’
J-PlatPatç­‰ã§CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—
æœ¬ã‚·ã‚¹ãƒ†ãƒ ã«èª­ã¿è¾¼ã‚€
```
                """)

        with st.expander("ğŸ“Œ ç²¾åº¦ï¼ˆPrecisionï¼‰ã¨å†ç¾ç‡ï¼ˆRecallï¼‰ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•"):
            st.markdown("""
**ã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹èª¿æŸ»ã«ãŠã‘ã‚‹è€ƒãˆæ–¹:**

```
å†ç¾ç‡ï¼ˆRecallï¼‰= å®Ÿéš›ã®é–¢é€£ç‰¹è¨±ã®ã†ã¡ä½•ä»¶ç™ºè¦‹ã§ããŸã‹

   å†ç¾ç‡100%ã‚’ç›®æŒ‡ã™å ´åˆ:
   â†’ å…¨ä»¶ç¢ºèªï¼ˆã‚³ã‚¹ãƒˆå¤§ã€ç¾å®Ÿçš„ã§ãªã„ï¼‰

   å†ç¾ç‡ 60% ã§ã¯:
   â†’ é‡è¦ãªé–¢é€£ç‰¹è¨±ã®40%ã‚’è¦‹é€ƒã™å¯èƒ½æ€§
   â†’ ã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹ãƒªã‚¹ã‚¯ãŒæ®‹ã‚‹

â†’ ã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹èª¿æŸ»ã§ã¯å†ç¾ç‡ã‚’æœ€å„ªå…ˆã«è¨­å®š
```

**ç¢ºèªæ•°ï¼ˆKï¼‰ã‚’å¢—ã‚„ã™ã¨:**
- å†ç¾ç‡ã¯ä¸ŠãŒã‚‹ï¼ˆè¦‹é€ƒã—ãŒæ¸›ã‚‹ï¼‰
- ç²¾åº¦ã¯ä¸‹ãŒã‚‹ï¼ˆç¢ºèªãŒå¢—ãˆã‚‹ï¼‰

**æœ¬ã‚·ã‚¹ãƒ†ãƒ ã® Precision/Recall ãƒ†ãƒ¼ãƒ–ãƒ«ã®èª­ã¿æ–¹:**

| ç¢ºèªæ•°(K) | ç²¾åº¦ | å†ç¾ç‡ |
|-----------|------|--------|
| 10 | 0.80 | 0.40 | â† 10ä»¶è¦‹ã¦ã‚‚é–¢é€£ç‰¹è¨±ã®40%ã—ã‹ã‚«ãƒãƒ¼ã§ããªã„ |
| 30 | 0.60 | 0.90 | â† 30ä»¶ç¢ºèªã™ã‚Œã°é–¢é€£ç‰¹è¨±ã®90%ã‚’ã‚«ãƒãƒ¼ âœ… |
| 50 | 0.40 | 1.00 | â† 50ä»¶è¦‹ã‚Œã°å…¨ä»¶ã‚«ãƒãƒ¼ï¼ˆã‚³ã‚¹ãƒˆãŒé«˜ã„ï¼‰ |

èª¿æŸ»å·¥æ•°ã¨è¦‹é€ƒã—ãƒªã‚¹ã‚¯ã®ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚Šã€**ç¢ºèªæ•°ã‚’æ±ºå®šã™ã‚‹ã€‚**
            """)

        with st.expander("ğŸ“Œ ãƒ•ãƒªãƒ¼ãƒ©ãƒ ãƒ¬ãƒ¼ãƒ»ãƒãƒ¼ãƒ•ãƒªãƒ¼å®šç†ï¼ˆNFLå®šç†ï¼‰"):
            st.markdown("""
**è«–æ–‡ã§è¨€åŠã•ã‚Œã¦ã„ã‚‹NFLå®šç†ï¼ˆNo Free Lunch Theoremï¼‰:**

> ã€Œã‚ã‚‰ã‚†ã‚‹å•é¡Œã«å¯¾ã—ã¦æœ€é©ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯å­˜åœ¨ã—ãªã„ã€

ã“ã‚Œã¯æ©Ÿæ¢°å­¦ç¿’ã®é‡è¦ãªå®šç†ã§ã€

- ã€Œç‰¹è¨±èª¿æŸ»ã«å¸¸ã«æœ€è‰¯ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€ã¯ãªã„
- ãƒ‡ãƒ¼ã‚¿ã®ç‰¹æ€§ï¼ˆæŠ€è¡“åˆ†é‡ã€èªå½™ã€æ–‡æ›¸é‡ï¼‰ã«ã‚ˆã£ã¦æœ€è‰¯ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯å¤‰ã‚ã‚‹
- â†’ ã ã‹ã‚‰æœ¬ã‚·ã‚¹ãƒ†ãƒ ã§ã¯ **13ç¨®é¡ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’æ¯”è¼ƒ** ã—ã¦æœ€é©ãªã‚‚ã®ã‚’é¸ã¶è¨­è¨ˆã«ãªã£ã¦ã„ã‚‹

**å®Ÿè·µã¸ã®ç¤ºå”†:**
- æœ€åˆã‹ã‚‰ç‰¹å®šã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«æ±ºã‚ãšã«è¤‡æ•°ã‚’è©¦ã™
- è‡ªç¤¾ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ©ãƒ™ãƒ«ä»˜ãç‰¹è¨±ï¼‰ã§å®Ÿéš›ã«è©•ä¾¡ã™ã‚‹
- å®šæœŸçš„ã«ãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°ãƒ»è©•ä¾¡ã—ç›´ã™
            """)

        with st.expander("ğŸ“Œ ã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚»ãƒƒãƒˆã®å­ã®å®šç†ï¼ˆã‚¯ãƒ¬ãƒ¼ãƒ ã®èª­ã¿æ–¹ï¼‰"):
            st.markdown("""
**è«–æ–‡ã§è¨€åŠã•ã‚Œã¦ã„ã‚‹ç‰¹è¨±ã‚¯ãƒ¬ãƒ¼ãƒ è§£é‡ˆã®åŸºæœ¬åŸå‰‡:**

ã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹èª¿æŸ»ã§ã¯ã€Œæ–‡è¨€ä¾µå®³ã€ã®åˆ¤æ–­ãŒåŸºæœ¬ã¨ãªã‚Šã¾ã™ãŒã€
å‡ç­‰è«–ãƒ»ä¸Šä½æ¦‚å¿µã§ã®ä¾µå®³ã«ã‚‚æ³¨æ„ãŒå¿…è¦ã§ã™ã€‚

**ã‚¯ãƒ¬ãƒ¼ãƒ è¦ç´ ã®ã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚»ãƒƒãƒˆï¼ˆä¸Šä½æ¦‚å¿µï¼‰å•é¡Œ:**
- è‡ªç¤¾è£½å“ã®è¦ç´ ãŒã€ä»–ç¤¾ç‰¹è¨±ã‚¯ãƒ¬ãƒ¼ãƒ ã®ä¸Šä½æ¦‚å¿µã«å«ã¾ã‚Œã‚‹å ´åˆã¯ä¾µå®³ã«ãªã‚Šã†ã‚‹
- ä¾‹: ä»–ç¤¾ç‰¹è¨±ã€Œãƒãƒªãƒ“ãƒ‹ãƒ«ã‚¢ãƒ«ã‚³ãƒ¼ãƒ«ç³»æ¨¹è„‚ã‚’å«ã‚€ã‚³ãƒ¼ãƒ†ã‚£ãƒ³ã‚°å±¤ã€
  â†’ è‡ªç¤¾è£½å“ã«ã€Œãƒãƒªãƒ“ãƒ‹ãƒ«ã‚¢ãƒ«ã‚³ãƒ¼ãƒ«ã®ã‚³ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã€ãŒã‚ã‚Œã° â†’ ä¾µå®³ã®å¯èƒ½æ€§

**æœ¬ã‚·ã‚¹ãƒ†ãƒ ã®ã€Œæ§‹æˆè¦ç´ å˜ä½ã®é¡ä¼¼åº¦åˆ†æã€:**
- å„ã‚¯ãƒ¬ãƒ¼ãƒ ã®æ§‹æˆè¦ç´ (a,b,c...)ã«åˆ†è§£ã—ã¦é¡ä¼¼åº¦ã‚’è¨ˆç®—
- ã©ã®è¦ç´ ãŒå€™è£œç‰¹è¨±ã«å«ã¾ã‚Œã¦ã„ã‚‹ã‹ã‚’æ ¹æ‹ æ–‡ãƒ¬ãƒ™ãƒ«ã§ç‰¹å®š
- ã‚ˆã‚Šç²¾ç·»ãªä¾µå®³ãƒªã‚¹ã‚¯ã®äº‹å‰è©•ä¾¡ãŒå¯èƒ½
            """)

        with st.expander("ğŸ“Œ æ­£è§£å…¬å ± / ãƒã‚¤ã‚ºå…¬å ± ã®è€ƒãˆæ–¹"):
            st.markdown("""
**è«–æ–‡ï¼ˆç‰¹è¨±æ–‡æ›¸ã®2ã‚¯ãƒ©ã‚¹åˆ†é¡ï¼‰ã®ç”¨èª:**

| ç”¨èª | æ„å‘³ | æœ¬ã‚·ã‚¹ãƒ†ãƒ ã® `label` å€¤ |
|------|------|----------------------|
| **æ­£è§£å…¬å ±ï¼ˆã‚·ã‚°ãƒŠãƒ«ï¼‰** | ã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹èª¿æŸ»ã§é–¢é€£ã™ã‚‹ã¨åˆ¤æ–­ã•ã‚ŒãŸç‰¹è¨± | `1` |
| **ãƒã‚¤ã‚ºå…¬å ±** | é–¢é€£ã—ãªã„ã¨åˆ¤æ–­ã•ã‚ŒãŸç‰¹è¨± | `0` |

**æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆæ–¹æ³•:**
1. éå»ã®ã‚¯ãƒªã‚¢ãƒ©ãƒ³ã‚¹èª¿æŸ»çµæœã‚’åˆ©ç”¨ã™ã‚‹
2. å¼ç†å£«ãƒ»ç ”ç©¶è€…ãŒæ‰‹å‹•ã§ãƒ©ãƒ™ãƒ«ã‚’ä»˜ã‘ã‚‹ï¼ˆæœ¬æ ¼é‹ç”¨ã«å¿…é ˆï¼‰
3. IPC/FIåˆ†é¡ã‚’æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦åˆ©ç”¨ã™ã‚‹

**æ•™å¸«ãƒ‡ãƒ¼ã‚¿æ•°ã®ç›®å®‰:**
- æœ€ä½: å„ã‚¯ãƒ©ã‚¹10ä»¶ä»¥ä¸Šï¼ˆåˆè¨ˆ20ä»¶ï¼‰
- æ¨å¥¨: å„ã‚¯ãƒ©ã‚¹50ä»¶ä»¥ä¸Šï¼ˆåˆè¨ˆ100ä»¶ï¼‰
- ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°æ´»ç”¨: 500ä»¶ä»¥ä¸ŠãŒæœ›ã¾ã—ã„

**è«–æ–‡ã®å®Ÿé¨“è¦æ¨¡:**
- æ­£è§£å…¬å ±: 49ä»¶ / ãƒã‚¤ã‚ºå…¬å ±: 705ä»¶ / åˆè¨ˆ: 754ä»¶
            """)

    st.divider()
    st.markdown("""
### å‚è€ƒæ–‡çŒ®
- å®‰è—¤ä¿Šå¹¸.ã€Œæ©Ÿæ¢°å­¦ç¿’ã‚’ç”¨ã„ãŸåŠ¹ç‡çš„ãªç‰¹è¨±èª¿æŸ» â€• ã‚¢ã‚¸ã‚¢ç‰¹è¨±æƒ…å ±ç ”ç©¶ä¼šã«ãŠã‘ã‚‹ç ”ç©¶æ´»å‹•ç´¹ä»‹ã€
  *tokugikon* 2018.11.26. no.291, pp.50-64.
- Yoon Kim. "Convolutional Neural Networks for Sentence Classification". *arXiv:1408.5882* (2014).
- Quoc Le, Tomas Mikolov. "Distributed Representations of Sentences and Documents". *ICML 2014*.
- Moen & SalimÃ¤ki. "Sparse Composite Document Vectors". *arXiv:1612.06778* (2016).
    """)
